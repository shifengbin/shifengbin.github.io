<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Posts on Blog Zone</title>
    <link>https://shifengbin.github.io/posts/</link>
    <description>Recent content in Posts on Blog Zone</description>
    <image>
      <title>Blog Zone</title>
      <url>https://shifengbin.github.io/images/cover.jpg</url>
      <link>https://shifengbin.github.io/images/cover.jpg</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 12 May 2023 11:03:18 +0800</lastBuildDate><atom:link href="https://shifengbin.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>k8s 几种探针作用和用法</title>
      <link>https://shifengbin.github.io/posts/k8s/probs/</link>
      <pubDate>Fri, 12 May 2023 11:03:18 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/k8s/probs/</guid>
      <description>在 Kubernetes 中，探针（probes）是一种机制，用于检查容器是否处于正常状态以及容器是否可以接收流量。 Kubernetes 提供了三种类型的探针：存活探针（Liveness Probe）、就绪探针（Readiness Probe）和启动探针（Startup Probe）。
以下是这三种探针的作用和用法：
存活探针（Liveness Probe） 作用：检查容器中的进程是否仍在运行。如果进程崩溃或停止响应，Kubernetes 将重启容器。 用法：建议在容器的生命周期中始终使用存活探针，以确保容器的可靠性。例如，您可以配置一个存活探针来检查容器中的进程是否响应 HTTP 请求或 ping 命令。
示例 YAML 配置：
livenessProbe: httpGet: path: /healthz port: 8080 initialDelaySeconds: 5 periodSeconds: 10 该配置文件指示 Kubernetes 发送一个 HTTP GET 请求到容器的 /healthz 路径，并在容器启动后的 5 秒后开始检查容器的运行状况。检查频率为每隔 10 秒发送一次。
就绪探针（Readiness Probe） 作用：检查容器是否准备好接收流量。如果容器尚未准备好接收流量，则 Kubernetes 将不会将流量发送到容器。 用法：建议在容器需要一些额外的时间来启动的情况下使用就绪探针。例如，您可以配置一个就绪探针来检查容器是否存在必需的文件或数据库连接。
示例 YAML 配置：
readinessProbe: tcpSocket: port: 8080 initialDelaySeconds: 5 periodSeconds: 10 该配置文件指示 Kubernetes 检查容器是否可以在 8080 端口接收 TCP 连接，并在容器启动后的 5 秒后开始检查容器的运行状况。检查频率为每隔 10 秒发送一次。</description>
    </item>
    
    <item>
      <title>在WSL中配置gitlab/github SSH KEY</title>
      <link>https://shifengbin.github.io/posts/git/auth/</link>
      <pubDate>Mon, 08 May 2023 14:24:08 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/git/auth/</guid>
      <description>背景 在公司里普遍使用搭建的gitlab,很多情况下我们使用终端提交,这时候就会频繁的数据账户和密码,为了不输入密码我们会配置SSH KEY来免登录.
步骤 使用ssh-keygen 来生成公钥和私钥 使用ssh-keygen -t ed25519 或者 ssh-keygen -t rsa -b 2048 没什么特别的一路回车 这时候会在你~/.ssh/目录下生成密钥对 以rsa密钥为例,把~/.ssh/id_rsa.pub的内容配置到gitlab 测试使用ssh git@gitlab.xxx.com(你公司的域名)看下是否正常打印你的配置名称,如果不正常使用ssh -Tvvv git@gitlab.xxx.com打印调试信息,看是哪个地方出了问题 已经可以正常提交代码 可能出现的问题 ssh连接没问题,但是git会提示输入用户密码 这种情况看下自己仓库是否使用的是http连接, 如果是替换ssh链接就可以解决git remote set-url origin git@xxx.com:username/blog.git
使用go来拉取包时如果使用http地址拉取怎么办 可以使用Git提供的凭证存储器来配置HTTP协议的自动登录,Git提供了三种凭证存储器，分别是cache、store和osxkeychain。不同的存储器有各自的优缺点，例如cache存储器将凭证信息保存在内存中，store存储器将凭证信息保存在本地的plain-text文件中，osxkeychain存储器则将凭证信息保存到Mac的Keychain应用程序中.
可以使用git config --global credential.helper store来配置,然后随便拉取一个该域名的项目,输入账号密码就会存储到本地,后面就不会再要求输入用户密码</description>
    </item>
    
    <item>
      <title>go 编译指令build</title>
      <link>https://shifengbin.github.io/posts/go/build/</link>
      <pubDate>Tue, 07 Mar 2023 10:50:47 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go/build/</guid>
      <description>go:build 是 Go 1.17 版本中引入的一个构建标记，用于根据不同的条件控制代码的编译。go:build 格式如//go:build &amp;lt;标记表达式&amp;gt;, 1.17之前使用+build的方式,这里我们介绍更强大的的go:build.
表达式可以包含由 ||、&amp;amp;&amp;amp; 和 ! 运算符和括号组合的选项,含义与 Go 语言中相同.
构建约束可以出现在任何类型的源文件中（不仅仅是 Go 文件），但是它们必须出现在文件的顶部附近，仅由空行和其他行注释分隔。这些规则意味着在 Go 文件中，构建约束必须出现在包声明之前。
例如，下面的构建约束将约束一个文件在满足“linux”和“386”约束条件或在满足“darwin”条件且未满足“cgo”条件时进行构建：//go:build (linux &amp;amp;&amp;amp; 386) || (darwin &amp;amp;&amp;amp; !cgo)
自定义tag
//go:build atest
当我们使用go build -tags atest的情况下会编译此文件,否则不会编译
控制go版本
//go:build go1.17 指定当前文件&amp;gt;=go1.17才编译
//go:build go1.17 &amp;amp;&amp;amp; go1.20 版本&amp;gt;= go1.17 并且&amp;lt;= go1.20</description>
    </item>
    
    <item>
      <title>Intel hex文件格式</title>
      <link>https://shifengbin.github.io/posts/hd/intel_hex/</link>
      <pubDate>Mon, 27 Feb 2023 16:45:45 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/hd/intel_hex/</guid>
      <description>Intel HEX格式文件是一种常见的用于表示程序存储器内容的文本格式，常用于将程序存储器内容导出或者导入到不同的开发工具中。它的文件扩展名通常是 .hex。
该文件格式由一系列行组成，每一行以冒号(:)开头，以回车换行符(\r\n)结尾，每一行包含以下几个部分：
起始符号：一个字符，表示该行的起始，必须为“:”。
数据长度：一个字节，表示该行所包含的数据长度，以字节为单位，范围从 0 到 255。
起始地址：两个字节，表示该行数据在存储器中的起始地址，以字节为单位，高位在前，低位在后。
记录类型：一个字节，表示该行数据的类型。常见的记录类型包括数据记录（00）、结束记录（01）等。
数据：一个或多个字节，表示该行的数据内容。数据的长度由数据长度字段指定。
校验和：一个字节，表示该行数据的校验和，为数据长度、起始地址、记录类型和数据的按位异或和的补码。
例如
:10010000214601360121470136007EFE09D2190140 //起始符号是“:”。 //数据长度是“10”。 //起始地址是“0100”。 //记录类型是“00”，表示这是一个数据记录。 //数据部分包含了16个字节的数据：“214601360121470136007EFE09D21901”。 //校验和是“40”。 //这个数据记录包含了16个字节的数据，它们对应的起始地址是0x0100~0x010F。每两个字节表示一个数据，因此这个记录实际包含了8个数据，分别是“21 46 01 36 01 21 47 01 36 00 7E FE 09 D2 19 01”。 :00000001FF //起始符号是“:”。 //数据长度是“00”。 //起始地址是“0000”。 //记录类型是“01”，表示这是一个结束记录。 //数据部分为空。 //校验和是“FF”。 //这个记录表示文件结束。当解析Intel HEX格式文件时，如果读到了一个记录类型为“01”的记录，就表示已经读到了文件的结尾，应该停止解析。 记录类型 在Intel HEX格式文件中，一共定义了5种记录类型。它们分别是：
数据记录（Data Record），记录类型为“00”。
结束记录（End Of File Record），记录类型为“01”。
扩展段地址记录（Extended Segment Address Record），记录类型为“02”。
扩展线性地址记录（Extended Linear Address Record），记录类型为“04”。
起始段地址记录（Start Segment Address Record），记录类型为“03”。 其中，最常用的是数据记录和结束记录。其他三种记录类型则用于更高级的应用，如程序跳转、内存分段等。
举例:
数据记录（Data Record）：:10010000214601360121470136007EFE09D2190140 这是一条16字节的数据记录，其记录类型为“00”。数据部分为“214601360121470136007EFE09D21901”。</description>
    </item>
    
    <item>
      <title>go 编译指令Linkname</title>
      <link>https://shifengbin.github.io/posts/go/linkname/</link>
      <pubDate>Fri, 24 Feb 2023 14:35:25 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go/linkname/</guid>
      <description>go:linkename是go的编译指令,可以在一个包中使用另一个包中的非导出函数或变量
具体使用方法举例
在pkg1包中有个未导出的函数add
package pkg1 func add(a, b int) int { return a + b } 在pkg2中想要使用pkg1.add,正常来说add开头是小写是不能被另一个包使用的,这时候我们想要在另一个包中使用就有两种方法:
在pkg1中定义一个可以导出的函数,这种就是在写个Add函数包裹一下,这种就不举例了 在pkg2中使用linkname编译指令修改函数或变量的名称和可见性(不太建议) 这里我们举例第二种
package pkg2 import ( _ &amp;#34;goasm/pkg1&amp;#34; //需要引入pkg1, 让pkg1参与代码编译,否则编译器找不到, 这句也可以写在别的文件中,只要让pkg1参与编译就行, relocation target goasm/pkg1.add not defined _ &amp;#34;unsafe&amp;#34; //编译器要求导入unsafe包,否则不能使用linkname指令 ) //下面就是linkname编译指令使用方法, 在函数声明上添加注释, 其中pkg1_add是函数名称, goasm/pkg1.add 是要连接的函数, 这句指令的效果就是,调用pkg1_add就是在调用goasm/pkg1包中的add函数 //go:linkname pkg1_add goasm/pkg1.add func pkg1_add(a, b int) int func Add2(a, b int) int { return pkg1_add(a, b) } 总结: go:linkname的使用是依赖于编译器的实现，因此使用时需要慎重考虑其可维护性和可移植性。 总之了解就好,不是迫不得已不要真的使用</description>
    </item>
    
    <item>
      <title>Swap开启和关闭</title>
      <link>https://shifengbin.github.io/posts/k8s/swap/</link>
      <pubDate>Thu, 23 Feb 2023 15:37:31 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/k8s/swap/</guid>
      <description>树莓派 /etc/dphys-swapfile 是 Raspberry Pi 上的一个文件，用于控制swap文件的设置和使用。该文件用于设置swap文件的大小、位置以及启用和禁用swap。
在 Raspberry Pi 上，如果想要使用swap文件，可以通过以下步骤配置和使用swap文件：
安装 dphys-swapfile 包，使用命令： sudo apt-get update sudo apt-get install dphys-swapfile 打开 /etc/dphys-swapfile 文件，配置swap文件的大小和位置。例如，将以下行： CONF_SWAPSIZE=100 #修改为0可关闭swap CONF_SWAPFILE=/var/swap 启用 sudo dphys-swapfile setup sudo dphys-swapfile swapon 禁用 sudo dphys-swapfile swapoff 其他linux 在Linux中，可以通过以下步骤关闭swap：
查看当前的swap情况，使用命令： swapon -s 如果没有任何输出，则说明当前系统没有启用swap。
如果系统启用了swap，需要先关闭swap，使用命令： swapoff -a 执行此命令会关闭所有swap分区。
临时禁用swap，使用命令： echo 0 &amp;gt; /proc/sys/vm/swappiness 执行此命令可以临时禁用swap，即使系统启用了swap，也不会自动将数据交换到swap分区。
永久禁用swap，可以修改/etc/fstab文件，注释掉swap分区的行，或者直接删除swap分区的行。例如，将以下行： #/dev/sda2 swap swap defaults 0 0 </description>
    </item>
    
    <item>
      <title>针对循环查询的逻辑优化思路</title>
      <link>https://shifengbin.github.io/posts/optimization/logic/</link>
      <pubDate>Thu, 02 Feb 2023 17:06:48 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/optimization/logic/</guid>
      <description>在工作中总能碰见有人的接口使用循环查询数据库的情况,针对这种情况我总结了一些针对这种情况的初步优化思路.
限制和优点 限制 此种方法只针对循环查询这种类型的优化
优点 不用完全了解业务逻辑,即可完成有效的优化
方法 概述 先明确循环的位置, 以及循环内要查的数据 采用包一层的思路(计算机界没有什么是包一层不能解决的, 如果不能就再包一层😊), 把查询提前到循环外, 通过提供相同的查询逻辑(在内存里的查询),替换循环中的查询(数据库的查询),必须保证新的查询和老查询功能一致. 听起来好像没什么特别的,我们来看下具体实施过程
伪代码 假设有一个这种函数
func GetPersonList(xx) { ps := models.GetPersonByXX() for _, v := range ps { //xxxx很多逻辑,很复杂 orders := models.GetOrderByPerson(v.ID) //这里循环查数据库,我们需要看懂这块的查询条件和返回值 //xxx很多逻辑,很复杂 } } 我们可以这样优化
//1. 在models层实现一个批量查询接口 models.GetOrderByPersons(id ...int) //2. 包一层实现一个数据缓存结构 type OrderDataCache struct { order map[int/*person id */] []Order //这里的结构根据具体查询定义, 上述例子是通过person id查 } //3. 初始化数据缓存结构函数, 根据你具体的业务实现 func NewOrderDataCache(personID ....int) OrderDataCache { //调用批量查询 orders := models.GetOrderByPersons(id .</description>
    </item>
    
    <item>
      <title>Proto Plugin</title>
      <link>https://shifengbin.github.io/posts/micro_service/proto_plugin/</link>
      <pubDate>Wed, 19 Oct 2022 11:39:19 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/micro_service/proto_plugin/</guid>
      <description>1.插件命名规则 ​ proto插件名称需要使用protoc-gen-xxx
​ 当使用protoc &amp;ndash;xxx_out时就会调用proto-gen-xxx插件
2.protobuf解析一般流程 方法1: 先通过标准输入生成CodeGeneratorRequest 通过CodeGeneratorRequest初始化插件plugin 通过插件plugin获取文件File 遍历文件,处理内容,生成文件 像标准输出写入响应plugin.Response 示例代码:
s := flag.String(&amp;#34;a&amp;#34;, &amp;#34;&amp;#34;, &amp;#34;a&amp;#34;) flag.Parse() //生成Request input, _ := ioutil.ReadAll(os.Stdin) var req pluginpb.CodeGeneratorRequest proto.Unmarshal(input, &amp;amp;req) //设置参数,生成plugin opts := protogen.Options{ ParamFunc: flag.CommandLine.Set, } plugin, err := opts.New(&amp;amp;req) if err != nil { panic(err) } fmt.Fprintf(os.Stderr, &amp;#34;a=%s\n&amp;#34;, *s) // protoc 将一组文件结构传递给程序处理,包含proto中import中的文件 for _, file := range plugin.Files { if !file.Generate { //显示传入的文件为true continue } fmt.Fprintf(os.Stderr, &amp;#34;path:%s\n&amp;#34;, file.GoImportPath) genF := plugin.</description>
    </item>
    
    <item>
      <title>树莓派安装k8s</title>
      <link>https://shifengbin.github.io/posts/k8s/k8s/</link>
      <pubDate>Wed, 05 Oct 2022 20:49:13 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/k8s/k8s/</guid>
      <description>本地系统为树莓派官方64位系统 Raspberry Pi OS Lite 64(Debian GNU/Linux 11)
在master和node都需要执行的步骤 本机cgroup配置 在执行kubeadm init 时出现 missing required cgroup: memory时,可以在/boot/cmdline.txt(有的系统可能在/boot/firmware/cmdline.txt)中追加 cgroup_enable=memory cgroup_memory=1
cgroup_enable=memory: 启用Cgroup子系统中的内存控制 cgroup_memory=1: 将内存控制子系统的版本设置为1
在某些特定的发行版中，可能会出于兼容性或其他原因而禁用了Cgroup子系统中的内存控制功能,所以需要手动开启
关闭swap 网上很多教程通过编辑/etc/fstab编辑swap, 但是在树莓派系统中,并不使用fstab配置,正确的做法是
编辑/etc/dphys-swapfile 找到配置项CONF_SWAPSIZE (通过名称我们可以知道该配置项为swap大小)该值配置为0 使配置生效 sudo /etc/init.d/dphys-swapfile restart 或者 sudo reboot 重启 通过free -h命令查看swap大小
系统模块加载 # 必要的模块加载 # overlay 文件系统 # br_netfilter 网桥网络包过滤 cat &amp;lt;&amp;lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF # 这个命令会将 &amp;#34;overlay&amp;#34; 和 &amp;#34;br_netfilter&amp;#34; 内核模块的名称添加到 /etc/modules-load.d/k8s.conf 文件中，以便在系统启动时自动加载这些模块 sudo modprobe overlay sudo modprobe br_netfilter # sudo modprobe overlay：加载 overlay 的内核模块，该模块提供了用于 overlayfs 的文件系统类型。在使用容器化技术如 Docker 时，通常需要使用 overlayfs 进行容器镜像的存储和管理。因此，在启用容器化环境时，需要确保该模块已加载。 # sudo modprobe br_netfilter：加载 br_netfilter 的内核模块，该模块提供了用于 Linux 桥接网络的过滤和 NAT 功能。在使用 Kubernetes 集群时，通常需要将容器内部的网络流量转发到主机上的网络设备，以实现容器与外部网络的通信。因此，在启用 Kubernetes 集群时，需要确保该模块已加载。 # 开启转发和流量可观测(开机启动) # sysctl params required by setup, params persist across reboots # bridge-nf-call-iptables 让ip表可以看到桥接流量 # bridge-nf-call-ip6tables 让ip6表可以看到桥接流量 cat &amp;lt;&amp;lt;EOF | sudo tee /etc/sysctl.</description>
    </item>
    
    <item>
      <title>树莓派系统关闭swap</title>
      <link>https://shifengbin.github.io/posts/pi/swap/</link>
      <pubDate>Sun, 02 Oct 2022 21:10:36 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/pi/swap/</guid>
      <description>网上很多教程通过编辑/etc/fstab编辑swap, 但是在树莓派系统中,并不使用fstab配置,正确的做法是
编辑/etc/dphys-swapfile 找到配置项CONF_SWAPSIZE (通过名称我们可以知道该配置项为swap大小)该值配置为0 使配置生效 sudo /etc/init.d/dphys-swapfile restart 或者 sudo reboot 重启 通过free -h命令查看swap大小</description>
    </item>
    
    <item>
      <title>Qemu&#43;gdb裸机调试</title>
      <link>https://shifengbin.github.io/posts/os/qemu_gdb/</link>
      <pubDate>Fri, 23 Sep 2022 16:31:24 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/os/qemu_gdb/</guid>
      <description>假设我们有一个boot.bin裸机汇编程序 我们想用qemu进行调试
我们可以使用qemu-system-x86_64 -s -S boot.bin
参数说明:
-s 可以使qemu开启1234端口,方便我们使用gdb连接调试
-S 可以让qemu暂停执行,等待我们使用gdb发送调试命令
gdb 连接:
使用gdb命令,进入gdb后使用target remote 127.0.0.1:1234连接到qemu</description>
    </item>
    
    <item>
      <title>errgroup</title>
      <link>https://shifengbin.github.io/posts/go_source/errgroup/</link>
      <pubDate>Tue, 06 Sep 2022 17:22:20 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go_source/errgroup/</guid>
      <description>errgroup是一个很简单的工具包,总共代码量加上注释和空行才100来行
作用就是方便执行的任务,比如
g := errgroup.Group{} g.Go(func1) g.Go(func2) if err := g.Wait(); err != nil { //... } 结构
type Group struct { cancel func() //context 取消函数 wg sync.WaitGroup //用来等待全部执行完成 sem chan token //用来控制并发数 errOnce sync.Once //控制err字段只赋值一次 err error //错误 } 主要函数
func (g *Group) Go(f func() error) { if g.sem != nil { g.sem &amp;lt;- token{} //限制并发数, 并发数由管道能容纳下的token个数决定 } g.wg.Add(1) go func() { defer g.done() if err := f(); err !</description>
    </item>
    
    <item>
      <title>AMQP 0-9-1协议</title>
      <link>https://shifengbin.github.io/posts/net/amqp/</link>
      <pubDate>Tue, 02 Aug 2022 11:06:49 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/net/amqp/</guid>
      <description>约定 下面出现的无特殊说明都是按下面对应关系
Publishers(发布者/生产者)
Consumers(消费者)
Exchanges(交换机)
Broker(中间件)
Queues(队列)
Bingdings(绑定)
AMQP是什么 AMQP是Advanced Message Queuing Protocol的缩写,高级消息队列协议,是一种消息传递协议
中间件和角色 消息中间件从Publishers(发布者/生产者)接收消息,路由到Consumers(消费者)
因为AMQP是网络协议, 发布者,消费者,中间件能够在不同的机器上.
AMQP模型简介 AMQP模型有下面的视角:
消息被发布到交换机(exchange,通常被比作邮局或邮箱) 交换机(exchanges)根据绑定(bindings)规则把消息复制到队列(queues) 中间件(borker)把消息投递到订阅队列或者从队列中拉取的消费者(consumers) 当一个消息发布时, 生产者可以设置一些消息属性(消息元数据meta data).一些元数据被中间件使用,剩下其他的被不透明发送到中间件给应用程序使用.
网络是不可靠的,应用也有可能处理消息失败,AMQP 0-9-1有一个消息应答(acknowledgements)的概念:当一个消息派发给消费者,消费者会通知中间件,可以自动执行或者开发者选择执行.当使用消息确认时,收到消息的通知就会从队列里删除该消息.
在某些情况,比如一个消息无法被路由,消息将会返回给生产者,丢弃,或者如果中间件实现一个扩展放入死信队列.生产者通过发布消息携带某些参数来处理这些情况.
队列(queue)、交换机(exchanges)和绑定(bingdings)统称为AMQP实体.
AMQP是一个可编程的协议 AMQP是一种可编程协议，AMQP的实体和路由方案主要由应用程序自己定义，而不是由中间件管理员定义.因此，为声明队列和交换机、定义它们之间的绑定、订阅队列等操作做出了规定.
这给应用程序开发者很大的自由,但是这也要求他们意识到潜在的定义冲突,在实践中定义冲突很少，通常是配置错误。
应用定义他们需要的实体,定义必要的路由规则和不在使用时删除实体
交换机和交换机类型 交换机是向其发送消息的AMQP实体,交换机接收消息并将其路由到零个或多个队列中。使用的路由算法取决于交换机类型和绑定,AMQP协议提供四种交换机类型:
交换机类型 默认名称 Direct exchange(直接交换机) (Empty string) and amq.direct Fanout exchange(扇出交换机) amq.fanout Topic exchange(主题交换机) amq.topic Headers exchange(头交换机) amq.match (and amq.headers in RabbitMQ) 除了交换机类型之外，交换机还使用许多属性来声明，其中最重要的是:
Name (名称) Durability (中间件重启后持久化) Auto-delete (最后一个队列解除绑定自动删除) Arguments (参数,可选的, 由插件和中间件特定功能使用) 交换机可以是持久的或者是临时的,持久性交换机在中间件重启后仍能存在，而暂时性交换机则不能.并非所有场景和用例都要求交换机持久化.
默认交换机 默认交换机是一个没有名称预定义在broker的直接交换机(direct exchange),它有一个特殊的特性，这使得它对于简单的应用程序非常有用:每个被创建的队列都会用和队列名称相同的路由键(routing key)自动绑定默认交换机.</description>
    </item>
    
    <item>
      <title>Fisher-Yates Shuffle</title>
      <link>https://shifengbin.github.io/posts/algorithm/shuffle/</link>
      <pubDate>Wed, 27 Jul 2022 11:41:33 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/algorithm/shuffle/</guid>
      <description> 这个算法发是今天看了一个go的代码库看到的,通过lo库看到有个Shuffle函数点进去看了一下,调用的数标准库中的shuffle算法,看了一下介绍,感觉有点意思,记录一下
Fisher-Yates算法是什么 Fisher-Yates算法 是一种生成随机排列的算法
核心原理 — To shuffle an array ‘a’ of ‘n’ elements: //对于一个规模为n的集合 for i from n-1 down to 1 do //从后向前遍历 j = random integer such that 0 &amp;lt;= j &amp;lt;= i //随机一个从0-i数字 exchange a[j] and a[i] //交换随机下标和当前下标的元素交换 用语言描述就是:
从后向前遍历 随机一个下标范围是0到当前下标,(范围包含当前下标是因为可能不交换) 交换随机下标指向的值和当前下标指向的值 go语言描述 func init(){ rand.Seed(time.Now().Unix()) } func Shuffle[T any](t []T) { for i := len(t) - 1; i &amp;gt; 0; i-- { j := rand.Int() % (i + 1) t[i], t[j] = t[j], t[i] } } </description>
    </item>
    
    <item>
      <title>语法图</title>
      <link>https://shifengbin.github.io/posts/compiler/syntax_graph/</link>
      <pubDate>Thu, 07 Jul 2022 18:00:27 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/compiler/syntax_graph/</guid>
      <description>语法图又称铁路图，是EBNF(扩展巴克斯范式)的图形化表示
从左边界开始沿着轨道去到右边界。 沿途，你将在圆框中遇到的是字面量，在方块中遇到的是规则或者描述。 任何沿着轨道能走通的序列都是合法的。 任何不能沿着轨道走通的序列都是非法的。 /* a simple program in EBNF − Wikipedia */ program ::= &amp;#39;PROGRAM&amp;#39; whiteSpace identifier whiteSpace &amp;#39;BEGIN&amp;#39; whiteSpace (assignment &amp;#34;;&amp;#34;)* &amp;#39;END.&amp;#39; assignment ::= identifier &amp;#34;:=&amp;#34; ( number | identifier | string ) string ::= &amp;#39;&amp;#34;&amp;#39; [A-Z0-9_]+ &amp;#39;&amp;#34;&amp;#39; identifier ::= [A-Z] [0-9A-Z]* whiteSpace ::= [#x20] </description>
    </item>
    
    <item>
      <title>EBNF</title>
      <link>https://shifengbin.github.io/posts/compiler/ebnf/</link>
      <pubDate>Tue, 05 Jul 2022 15:31:12 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/compiler/ebnf/</guid>
      <description>EBNF 扩展巴科斯-瑙尔范式(EBNF, Extended Backus–Naur Form) 是表达作为描述计算机编程语言形式语言(是用精确的数学或机器可处理的公式定义的语言) 的正规方式的上下文无关文法 的元语法(metalanguage)符号表示法。它是巴科斯范式(BNF) 元语法符号表示法的一种扩展。
简单的理解就是用来描述语言词法和语法规则的语言
ISO/IEC 14977标准 基本形式 LEFT=RIGHT 意思为LEFT可由RIGHT推导而来，LEFT为非终结符，RIGHT可以为非终结符也可以为终结符； 非终结符 简单的理解就是可以继续推导的符号 终结符 不可被推导的符号
符号 符号 含义 示例 = 定义 CharA=&amp;ldquo;a&amp;rdquo;; 代表CharA由字母a推导而来 , 连接符 a,b,c 代表abc是挨着的 ; 结束符 CharA=&amp;ldquo;a&amp;rdquo;; 代表 CharA这条语句定义结束 | 或者 digit = &amp;ldquo;0&amp;rdquo; | &amp;ldquo;1&amp;rdquo; | &amp;ldquo;2&amp;rdquo; | &amp;ldquo;3&amp;rdquo; | &amp;ldquo;4&amp;rdquo; | &amp;ldquo;5&amp;rdquo; | &amp;ldquo;6&amp;rdquo; | &amp;ldquo;7&amp;rdquo; | &amp;ldquo;8&amp;rdquo; | &amp;ldquo;9&amp;rdquo;; [&amp;hellip;] 可选，出现0次或1次 number = [&amp;quot;-&amp;quot;|&amp;quot;+&amp;quot;],digit 可匹配 1 -1 +1 &amp;hellip; {&amp;hellip;} 重复，出现&amp;gt;=0次 number = [&amp;quot;-&amp;quot;|&amp;quot;+&amp;quot;],digit,{digit} 可匹配 1 -1 +1 11 &amp;hellip; (&amp;hellip;) 分组 number = （&amp;quot;-&amp;quot;|&amp;quot;+&amp;quot;）,digit 符号必须添加，可匹配 -1 +1 &amp;hellip; &amp;ldquo;&amp;hellip;&amp;ldquo;或者&amp;rsquo;&amp;hellip;&#39; 终结符,单引号主要是一些特殊情况，比如双引号 &amp;ldquo;a&amp;quot;或者&amp;rsquo;a&amp;rsquo; 由单或双引号引起来的部分是终结符，就是代表字母a，不可继续推导 (* &amp;hellip; *) 注释 (*我是注释*) 注释不参与定义 ?</description>
    </item>
    
    <item>
      <title>计算机网络简要概述</title>
      <link>https://shifengbin.github.io/posts/net/summary/</link>
      <pubDate>Mon, 04 Jul 2022 21:10:39 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/net/summary/</guid>
      <description>计算机网络分层 市面上对网络分层主要是有三种分层
七层 五层 四层 应用层 应用层 应用层 表示层 会话层 传输层 传输层 传输层 网络层 网络层 网络层 数据链路层 数据链路层 网络接口层 物理层 物理层 每层的职责 物理层 提供物理介质,电压信号等功能
数据链路层 提供P2P传输 (点对点的, 比如一个路由器到另一个路由器)
网络层 提供E2E传输 (Endpoint to Endpoint,两个端点的传输,中间可能经过若干个路由器,注意区别P2P, E2E &amp;gt; P2P)
传输控制层 提供进程到进程的传输(端口到端口的传输)
应用层 应用自定义个协议
每一层都是通过下层对上层提供接口的形式来提供服务
常用网络设备 交换机 交换机工作在数据链路层, 通过mac地址进行转发, 全双工网络设备, 可以隔离碰撞域, 减少链路上的信号碰撞,提高链路网络利用率
路由器 路由器工作在网际层, 通过ip进行转发, 全双工网络设备, 可以隔离广播域(广播不能通过路由器)</description>
    </item>
    
    <item>
      <title>Semaphore(信号量)</title>
      <link>https://shifengbin.github.io/posts/go_source/semaphore/</link>
      <pubDate>Fri, 01 Jul 2022 23:51:45 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go_source/semaphore/</guid>
      <description>信号量 信号量(Semaphore)，有时被称为信号灯，是在多线程环境下使用的一种设施，是可以用来保证两个或多个关键代码段不被并发调用。在进入一个关键代码段之前，线程必须获取一个信号量；一旦该关键代码段完成了，那么该线程必须释放信号量
简单的说就是通过获取资源和释放资源来进行同步的一种策略
用法 用法一共有以下几步:
创建信号量 获取信号量 释放信号量 //1.创建信号量为10 sem = semaphore.NewWeighted(10) for i := 0; i &amp;lt;100; i++ { go func() { ctx := context.TODO() //2.获取一个信号量, 信号量一共10个,获取最多获取10,超过的gorutine会挂起 if err := sem.Acquire(ctx, 1); err != nil { doSomething() } //3. 释放信号量,1个 sem.Release(1) }() } 代码解读 Weighted 结构(NewWeighted 返回的数据结构) type Weighted struct { size int64 //总大小,就是NewWeighted传入的个数 cur int64 //当前消耗的个数 mu sync.Mutex //互斥锁 waiters list.List //等待列表, 当信号量不足时等待的列表 } waiter 结构(等待列表保存的结构) type waiter struct { n int64 //需要的资源数 ready chan&amp;lt;- struct{} // 用来通知gorutine } Acquire 方法 func (s *Weighted) Acquire(ctx context.</description>
    </item>
    
    <item>
      <title>K3s安装</title>
      <link>https://shifengbin.github.io/posts/pi/k3s/</link>
      <pubDate>Wed, 29 Jun 2022 00:02:05 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/pi/k3s/</guid>
      <description>安装步骤 根据官方文档使用 curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh - 一条命令安装
安装过程的坑 建议使用Raspberry OS, 之前使用过Ubuntu 22.04 安装后发生节点有时Ready有时NotReady反复横跳, 最后用Raspberry OS安装成功 Raspberry也有点小坑,需要在/boot/cmdline.txt文件最后用空格,不要换行, 添加cgroup_memory=1 cgroup_enable=memory, 然后重启 `` 官方文档 </description>
    </item>
    
    <item>
      <title>链路追踪</title>
      <link>https://shifengbin.github.io/posts/micro_service/trace/</link>
      <pubDate>Mon, 27 Jun 2022 14:24:23 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/micro_service/trace/</guid>
      <description>链路追踪是什么 链路追踪是在分布式条件下将一个请求还原成一个完整调用链条,可以分析调用拓扑,延迟分析,性能分析.
链路追踪的好处 分析网络,服务耗时(通过链路追踪事件可以知道网络延迟,服务延迟) 分析网络拓扑(链路分析) 故障定位(配合日志,进行故障定位) 原理 Trace Trace代表一个调用链路,通过TraceID来标记, 一次请求调用的各个服务TraceID在全局都是唯一的
Span Span代表一个调用范围拥有(ParentID, SpanID), ParentID代表他的调用者SpanID, SpanID代表本层次调用id
通过TraceID标记一个完整调用链都调用了哪些调用过程, 通过ParendID,和SpanID还原了调用的父子关系
Annotation 通过上面三个ID只能还原调用关系, 还不能进行性能分析和定位,所以还要添加一些辅助的注解信息, 可以同定义事件比如: Client Send: 客户端调用开始 Client Receive: 客户端调用结束 Server Send: 服务端发送 Server Receive: 服务端接收
图一是一个调用关系图,展示了TraceID, SpanID, ParentID 之间的关系,和传递 其中,个方框是一个服务,箭头代表调用关系,一个完整调用链中trace是相同的, 每个服务有各自的SpanID, ParentID是调用方的SpanID, 通过这些ID我们可以知道调用的上下级关系
图二是通过Annotation附带信息进行性能分析,通过Client Send 到 Server Receive可以分析出请求服务的网络时延;通过Server Receive到Server Send可以分析出调用时延;同理Server Send到Client Receive分析出响应的网络时延, Client Send到Client Receive整个请求的时延</description>
    </item>
    
    <item>
      <title>Once</title>
      <link>https://shifengbin.github.io/posts/go_source/once/</link>
      <pubDate>Sat, 25 Jun 2022 20:50:16 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go_source/once/</guid>
      <description>once是什么 和singlefight有些相似,singlefight是并发执行时只有一个在执行, once也是并发时只有一个在执行,只不过,只执行一次,再次调用不会在执行
once怎么用 var A int var once = sync.Once{} func initA() int { once.Do(func() { //这里只会执行一次 A = 10 //A=10 只会执行一次,并且所有并发进来的,都需要等待A=10 完成后返回 }) return A // A=10 happens before 读取A, 所以initA()在所有gorutine里,都返回10 } 这个例子我们可以构造一个懒汉模式单例
源码阅读 Once结构 type Once struct { done uint32 m Mutex } Once结构很简单,只有两个字段, done来表示是否执行完成, m为互斥锁
Do函数 func (o *Once) Do(f func()) { //判断done 如果没完成,则执行doSlow函数,否则直接返回退出函数 if atomic.LoadUint32(&amp;amp;o.done) == 0 { o.doSlow(f) } } doSlow (第一次并发执行时才会进入的分支) func (o *Once) doSlow(f func()) { o.</description>
    </item>
    
    <item>
      <title>数据竞赛(Data Race)</title>
      <link>https://shifengbin.github.io/posts/go/datarace/</link>
      <pubDate>Thu, 23 Jun 2022 16:39:21 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go/datarace/</guid>
      <description> 没有安全的数据竞赛,不要使用各种炫技的无锁方式等骚操作! 什么是数据竞赛 并行程序在未使用同步方法(atomic, lock)的情况下, 并发读写共享资源就会造成数据竞争
数据竞赛检测原理 通过编译器注入检测代码, 检测代码会保存读写内存的 线程id, 时钟, 读写位置和长度, 是否写入等信息, 在运行的过程判断,读写内存是否有交叉,是否满足happens-before等条件,来判断数据竞赛
如何避免 使用同步方法去解决happens-before 比如使用atomic包, sync包 或者使用chan
go检测数据竞赛方法 使用go工具链 go build -race 编译一个带有数据竞赛检测的可执行程序,会在编译期插入代码,这种程序消耗内存和CPU是不带检测的数倍到数十倍,不可大范围用于生产环境
go run -race 直接运行一个带检测的程序(内部也经过编译)
go test -race 运行待检测的单元测试
go install -race 编译并安装一个待检测的可执行程序
注意数据竞赛检测是需要程序运行到有竞赛的代码才会检测到!运行不到的是不会检测出来的! </description>
    </item>
    
    <item>
      <title>go内存模型</title>
      <link>https://shifengbin.github.io/posts/go/memorymodel/</link>
      <pubDate>Thu, 23 Jun 2022 10:33:29 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go/memorymodel/</guid>
      <description>介绍 Go内存模型指定了一种条件，在这种条件下，可以保证读取一个goroutine中的变量，以观察不同goroutine中写入同一变量所产生的值。
建议 修改多个goroutine同时访问的数据必须序列化访问
序列化访问保护数据使用channel操作或者其他同步原语比如sync或者sync/atomic包
Happens before 在一个goroutine中,读写必须表现得就像它们按照程序指定的顺序执行一样;也就是说 在一个goroutine中,处理器和编译器可以重排读写的执行顺序,仅当重排后的行为不改变语言的设定.因为重排,一个goroutine观察到的执行顺序可能与另一个goroutine观察到的顺序不同.举个例子,如果一个goroutine执行a = 1; b = 2;,另一个可能会观察到b在a之前更新.
为了指定读写的需要，我们定义了在Go程序中执行内存操作的偏序(partial order)。如果事件$e_1$先发生于事件$e_2$我们说$e_2$后发生于$e_1$. 同样的如果$e_1$没有先发生于$e_2$并且$e_1$没有后发生于$e_2$那么我们说$e_1 e_2$同时发生.
在单个gorutine里, happens-before的顺序是程序表示的顺序.
如果下面两个条件成立,则允许变量v的读r 观察到对v的写w:
r没有先发生于w 没有其他对v的写w&amp;rsquo; ,后发生于w, 先发生于r (也就是在w 和 r之间不存在 w&#39;) 为了保证r能读到w的写,要确保w是允许r观察的唯一写入.也就是说，如果以下两个条件均成立，则保证r观察到w：
w先发生于r 任何其他写入共享变量v都要先发生于w或者后发生于r 这对条件比第一对更严格,这一对要求没有其他的写同时发生于w或r
在单个gorutine中没有并发,这两个定义是等价的:读r观察最近写入w到v的值.
在多个gorutine访问一个共享变量v,必须使用同步事件来建立happens-before条件来确保读到期望的写.
变量v的类型为零值时，变量v的初始化行为就像在内存模型中写入一样。(初始化等同于写入)
读写超过机器字(machine word)的行为就和以未指定的顺序执行多个机器字大小的操作一样(超过machine word 每个machine word 读取和写入顺序可能不是期望的)
总之, 想要在一个gorutine中读到另一个gorutine的写就要保证, 写在读之前发生,如果我们不加控制,这个写先于读的顺序就很难保证,所以我们需要使用atomic或者和lock机制来保证顺序保证happens-before
同步 初始化 程序初始化在单个goroutine中运行，但该goroutine可能会创建其他并发运行的goroutine。
如果包p导入包q，则q的init函数的完成时间在任何p的开始之前。
函数main的开始。main在所有init函数完成后发生。
Goroutine创建 启动新goroutine的go语句发生在goroutine开始执行之前。 举例
var a string func f() { print(a) } func hello() { a = &amp;#34;hello, world&amp;#34; go f() } 调用hello将在将来hello, world,可能hello已经返回</description>
    </item>
    
    <item>
      <title>false sharing</title>
      <link>https://shifengbin.github.io/posts/cpu/falsesharing/</link>
      <pubDate>Wed, 22 Jun 2022 15:04:38 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/cpu/falsesharing/</guid>
      <description>false sharing我们一般说的是多核的问题,这个问题主要出现在CPU的缓存上,我们知道CPU有多级缓存,而CPU缓存单单位是行(主流一个缓存行是64Byte, 也就是8个int64)
CPU加载缓存 当我们要操作一个变量A时会把A附近的64个字节都加载到缓存行中(空间局部性原理),这样在CPU的缓存里操作时要比在内存中要快
多核CPU缓存问题 在多核心中每个CPU核心都有自己的缓存,如果A和B变量是挨着的, 当CPU1要写A变量, CPU2读变量B, 因为AB挨着,CPU1和CPU2都把它们加载到自己的缓存中,并且AB在同一个缓存行中,CPU1改了A导致了CPU2中B缓存失效,CPUB就得重新从内存中加载缓存
这种情况就是&amp;quot;假共享&amp;quot;/&amp;ldquo;伪共享&amp;rdquo;/&amp;ldquo;false sharing&amp;rdquo;
说白了就是,CPU各自都有一份,因为邻近变量修改导致了其他核心缓存失效
例子 CASE1 type FS struct { X int64 Y int64 } func share() { var a FS wg := sync.WaitGroup{} wg.Add(2) start := time.Now() go func() { for i := 0; i &amp;lt; 100000000; i++ { a.X++ } wg.Done() }() go func() { for i := 0; i &amp;lt; 100000000; i++ { a.Y++ } wg.Done() }() wg.</description>
    </item>
    
    <item>
      <title>利特尔法则(等候理论,排队理论)</title>
      <link>https://shifengbin.github.io/posts/math/lite_rule/</link>
      <pubDate>Tue, 21 Jun 2022 22:44:01 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/math/lite_rule/</guid>
      <description>定义 在一个稳定的系统中，长期的平均顾客人数（L），等于长期的有效抵达率（λ），乘以顾客在这个系统中平均的等待时间（W）； 或者，我们可以用一个代数式来表达： $L=λW$
用白话说的话就是,在W时间内最多排多少人,能够让最后一个人也能在W时间内完成服务,也就是第一个人恰好出去,最后一个人恰好进来,这样最后一个人也能在W时间内出去
案例 就是说L的最后一名也可以在W时间内完成服务,按图上例子来说,就是4分钟内能同时服务多少个顾客 因为顾客的进入速度是2, 所以4分钟内最多也就是8个
如果进如速度是10那么4分钟就是40个
类比服务请求 如果一个请求的响应时长是1s, 系统的QPS是10/s, 那么系统同时处理请求的最佳个数是 10/s * 1s = 10个 如果系统里同时请求数超过10个,那么就会造成响应时间延长</description>
    </item>
    
    <item>
      <title>指数加权平均(EWA)</title>
      <link>https://shifengbin.github.io/posts/math/ewa/</link>
      <pubDate>Mon, 20 Jun 2022 17:44:00 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/math/ewa/</guid>
      <description>EWA是什么 EWA是以指数式递减加权的移动平均, 是一种近似平均(也可以理解为一段时间的平均值,因为越久的数据对当前的影响越小,小到一定程度就可以忽略,可以理解为一段时间的平均值)
基本公式 $V_t=βV_{t-1} + (1-β)R_t$
$V_t$ 代表t时刻的平均值
$βV_{t-1}$代表t-1时刻的平均值
$R_t$ 是t时刻的真实值
$β$ 范围在0-1之间
平均天数为 $N=\frac {1} {1-β}$
$β=0.5$则平均个数N=2 $β=0.9$则平均个数N=$\frac{1}{1-0.9}=10$ 也就是平均最近10次的
可以做什么 计算$\frac {1} {1-β}$个数据的平均值,减少噪声影响,平滑数据
好处比其他平均的好处是 不需要保存最近N次的数据,只需要保存上次计算的平均值</description>
    </item>
    
    <item>
      <title>hugo 支持github评论</title>
      <link>https://shifengbin.github.io/posts/hugo/comments/</link>
      <pubDate>Mon, 20 Jun 2022 15:02:41 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/hugo/comments/</guid>
      <description> 先在utteranc的configuration部分找到安装utteranc app到仓库,选择一个仓库并安装 在页面Enable Utterances部分找到js代码 在自己用的主题上找到关于comment的layout,把js代码添加到里面 运行 </description>
    </item>
    
    <item>
      <title>go sync包之singleflight原理</title>
      <link>https://shifengbin.github.io/posts/go_source/sync_singleflight/</link>
      <pubDate>Sun, 19 Jun 2022 22:02:23 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go_source/sync_singleflight/</guid>
      <description>singlefight是什么 singlefight 直译为&amp;quot;单飞&amp;quot;(雅名到底是啥我也不知道), 顾名思义就是只有一个跑了, 是用来对同一资源控制并发 多个goroutine访问同一个资源时,只有一个goroutine真正的进行访问,其他goroutine等待这一个goroutine返回后共享返回结果
为什么出现singlefight 这个包 上面是什么中已经交代,是为了控制访问同一个资源的并发数,举个例子:假设有个接口访问数据库中id为1的一条数据,如果我们没有控制并发,那么来一百个并发访问这个数据,那么这一百个请求全部取请求数据库(即使有缓存也是全部请求缓存)
如果我们使用了singlefight那么,100个并发讲只有一个请求去数据库,其他99个全部共享那1个返回的结果
怎么用 var g = singleflight.Group{} //初始化了一个singleflight func SharedRes(id int) (int, error) { key := fmt.Sprintf(&amp;#34;id:%d&amp;#34;, id) //同一个group上,相同key的,只会执行一次,也就是说用key标识一个共享资源 ret, err, _ := g.Do(key, func() (interface{}, error) { //调用共享资源 time.Sleep(time.Second) //这里睡1s是模拟资源执行的延迟 fmt.Println(&amp;#34;xxxx&amp;#34;) return 1, nil }) return ret.(int), err } func SingleFlight() { wg := sync.WaitGroup{} //为了等100个goroutine执行完,开启了一个WaitGroup for i := 0; i &amp;lt; 100; i++ { wg.Add(1) go func() { //模拟并发 ret, err := SharedRes(1) fmt.</description>
    </item>
    
    <item>
      <title>redis分布式锁</title>
      <link>https://shifengbin.github.io/posts/micro_service/redis_lock/</link>
      <pubDate>Sat, 18 Jun 2022 21:24:37 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/micro_service/redis_lock/</guid>
      <description>redis分布式锁网上方案很多,这里简单的介绍一种
加锁步骤 1.创建锁对象,内部创建一个随机数
2.使用SET KEY VALUE NX EX xxxSecond, 如果成功创建了KEY 则证明加锁成功VALUE 就是第一步创建的随机数 3.如果未能成功加锁需要不断取重试,直到超时或者获取锁
解锁步骤 解锁需要去判断KEY对应的值是否是创建时的随机数,如果不是就不能删除,只有是的时候才能删除,因为如果不是自己的随机数可能是因为锁过期被别人加锁了,不能去删除别人的锁, 检查和删除必须是原子操作,所以我们可以使用lua脚本保证原子操作
if redis.call(&amp;#34;GET&amp;#34;, KEYS[1])==ARGV[1] then redis.call(&amp;#34;DEL&amp;#34;, KEYS[1]) return true else	return false end 上面的lua脚本很容易懂,就是用来判断key对应的值是否是参数的值,如果是就删除key并返回成功,否则返回失败;失败的情况就是上述说的锁过期被其他程序加锁
优化 加锁是需要不断去重试,访问次数过多可能会给redis造成压力,比如100ms抢一次,一个线程1s钟要请求redis 10次, 如果是10线程抢锁,那么1s就是100次,抢锁的越多就会将redis请求数放大10倍 应对这种情况我们可以考虑,进程内部先去加互斥锁,解锁的时候去解互斥锁, 然后抢到锁的线程再去抢redis锁
优点: 这样如果有两个进程,各有5个线程去抢锁,则实际只有两个线程去访问redis,抢到锁后只有另一个进程的1个线程继续抢,这种已经在生产环境中得到实践
缺点: 造成锁竞争的不公平,同一个进程其他线程更容易抢到锁,因为互斥锁解锁同一个进程的其他线程可以更快的感知
还有一种想法未得到验证,通过redis的发布订阅来改进锁性能
锁过期问题,没有个安全的方法去估计过期时间 针对这种情况,可以考虑锁续期逻辑,比如默认过期时间是30s,我们到20s的时候去延长过期时间
可以考虑使用下面的续期逻辑
if redis.call(&amp;#34;GET&amp;#34;, KEYS[1]) == ARGV[1] then redis.call(&amp;#34;EXPIRE&amp;#34;, KEYS[1], ARGV[2]) return true else return false end 先去判断锁是否是自己的,如果是则进行续期
参考资料 redis set命令 从2.6.12版本开始，redis为SET命令增加了一系列选项
EX seconds – 设置键key的过期时间单位时秒
PX milliseconds – 设置键key的过期时间单位时毫秒</description>
    </item>
    
    <item>
      <title>树莓派 连接WIFI</title>
      <link>https://shifengbin.github.io/posts/pi/connect_wifi/</link>
      <pubDate>Sat, 18 Jun 2022 21:15:30 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/pi/connect_wifi/</guid>
      <description>ubuntu 22.04 进入 /etc/netplan/ 文件夹 cd /etc/netplan/ 编辑里面唯一一个文件，大概是：50-cloud-init.yaml sudo vim 50-cloud-init.yaml, 需要使用sudo,因为这个文件是root用户的问题件,或者把文件选项改成可写的 添加WIFI配置 network: ethernets: eth0: dhcp4: true optional: true wifis: # &amp;lt;----添加wifi配置节点 wlan0: dhcp4: true optional: true access-points: &amp;#34;wifi_name&amp;#34;: #&amp;lt;---- 这里填写填写你要连接的wifi名称 password: &amp;#34;xxxxx&amp;#34; #&amp;lt;-------这里填写wifi密码 version: 2 执行命令,生成网络配置sudo netplan generate 使网络配置生效sudo netplan apply 树莓派系统 在命令行中输入sudo raspi-config根选项配置即可(注意,可能不支持5G信号)</description>
    </item>
    
    <item>
      <title>Mac用网线连接树莓派</title>
      <link>https://shifengbin.github.io/posts/pi/pi_connect_mac/</link>
      <pubDate>Sat, 18 Jun 2022 16:12:36 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/pi/pi_connect_mac/</guid>
      <description> 首先 打开mac的系统偏好设置-&amp;gt;共享-&amp;gt;互联网共享（USB 10/100/1000 LAN） 并打开共享 打开终端查看树莓派分配的IP 使用arp -a 里面有个带有bridgeXXX的 IP 使用ssh命令 远程连接 </description>
    </item>
    
  </channel>
</rss>
