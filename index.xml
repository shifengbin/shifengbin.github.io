<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Blog Zone</title>
    <link>https://shifengbin.github.io/</link>
    <description>Recent content on Blog Zone</description>
    <image>
      <title>Blog Zone</title>
      <url>https://shifengbin.github.io/images/cover.jpg</url>
      <link>https://shifengbin.github.io/images/cover.jpg</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Thu, 04 Jul 2024 15:16:44 +0800</lastBuildDate><atom:link href="https://shifengbin.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kafka使用kraft搭建集群</title>
      <link>https://shifengbin.github.io/posts/mq/kafka_kraft/</link>
      <pubDate>Thu, 04 Jul 2024 15:16:44 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/mq/kafka_kraft/</guid>
      <description>主机准备
主机 IP 系统 kafka1 192.168.10.101 ubuntu22.04 kafka2 192.168.10.102 ubuntu22.04 kafka3 192.168.10.103 ubuntu22.04 主机环境
安装java 11 kafka_2.13-3.7.0 配置
这里部署的是broker和controller在一起的方式,也可以分别部署,具体修改kraft相关文件,配置都是相通的
kafka/config/kraft/server.properties
#集群角色 process.roles=broker,controller #每台机器的id不能一样 node.id=3 #这个是所有conntroller的地址,用于投票选举使用 controller.quorum.voters=1@192.168.10.101:9093,2@192.168.10.102:9093,3@192.168.10.103:9093 # 监听端口 listeners=PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093 # 客户端连接地址 advertised.listeners=PLAINTEXT://192.168.20.208:9092 # 日志地址, 这个修改到非/tmp目录,否则系统重启后会丢失 log.dirs=/var/log/kafka/kraft-combined-logs # ...其他配置按照实际情况修改 启动集群步骤:
KAFKA_CLUSTER_ID=&amp;quot;$(bin/kafka-storage.sh random-uuid)&amp;quot; 这个操作只在一个机器上运行,执行后记录这个值,这个是集群id,整个集群需要一致
bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c config/kraft/server.properties 每个机器上都要执行, 这个KAFKA_CLUSTER_ID 就是是上面执行的值
bin/kafka-server-start.sh config/kraft/server.properties 启动集群
配置systemd开机启动
在/etc/systemd/system/kafka.service文件中添加内容
[Unit] Description=Apache Kafka Server [Service] Type=simple User=root Group=root ExecStart=/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/kraft/server.properties ExecStop=/usr/local/kafka/bin/kafka-server-stop.sh Restart=on-failure [Install] WantedBy=multi-user.target 执行sudo systemctl daemon-reload 重新加载 执行sudo systemctl enable kafka 开机启动 执行sudo systemctl start kafka 启动 使用sudo journalctl -u kafka.</description>
    </item>
    
    <item>
      <title>Debezium</title>
      <link>https://shifengbin.github.io/posts/db/debezium/</link>
      <pubDate>Fri, 28 Jun 2024 11:15:28 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/db/debezium/</guid>
      <description>当我们想监控数据库数据变动时我可以使用一些CDC工具,这里介绍一款配合Kafka使用的Connect插件Debezium,他支持Mysql, PostgreSQL, MongoDB等
这里我们以MySQL为例
环境: 1. Kafka 3.7 2. MySQL 8.0 3. Debezium Mysql connect Plugin 2.6.2 Final Mysql: 需要开启row格式binlog
[mysqld] bind-address = 0.0.0.0 binlog_format = ROW server_id = 1 log_bin = /var/log/mysql/mysql-bin.log 需要以下权限
GRANT SELECT, RELOAD, SHOW DATABASES, REPLICATION SLAVE, LOCK TABLES, REPLICATION CLIENT ON *.* TO &amp;#39;user&amp;#39; IDENTIFIED BY &amp;#39;password&amp;#39;; 权限 作用 SELECT 查询数据,仅在执行快照时使用 RELOAD 允许连接器使用 FLUSH 语句来清除或重新加载内部缓存、刷新表或获取锁。仅在执行快照时使用 SHOW DATABASES 使连接器能够通过发出 SHOW DATABASE 语句来查看数据库名称。仅在执行快照时使用 REPLICATION SLAVE 使连接器能够连接并读取 MySQL 服务器二进制日志 REPLICATION CLIENT 允许连接器使用以下语句：SHOW MASTER STATUS,SHOW SLAVE STATUS,SHOW BINARY LOGS LOCK TABLES 执行快照时需要锁表 Debezium: 把插件解压到一个目录下,我这里解压到Kafka目录下,创建一个connects目录,解压到这里,解压后我的目录像这样 --kafka |--connects |--debezium-connector-mysql 在kafka的config文件夹下配置connect-distributed.</description>
    </item>
    
    <item>
      <title>Deadlock检测时机</title>
      <link>https://shifengbin.github.io/posts/go/deadlock/</link>
      <pubDate>Wed, 08 May 2024 17:52:55 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go/deadlock/</guid>
      <description>Go语言的运行时会在所有活跃的goroutine都无法继续执行时判定为死锁。这意味着，只要还有至少一个goroutine能够正常运行，Go运行时就不会触发死锁检测机制。死锁检测通常在以下情况下触发：
所有goroutine都阻塞：如果所有的goroutine都在等待某些事件（如通道操作、锁获取等），而这些事件无法由其他goroutine触发（因为没有其他goroutine在运行或者能够解除阻塞状态），Go运行时就会判定程序为死锁状态。(这里不包括io等待，因为io等待是阻塞的，但是go的运行时并不会触发死锁检测机制)
这种自动死锁检测主要是为了帮助开发者在开发阶段识别出潜在的并发问题。然而，它的能力是有限的，特别是在涉及网络I/O、系统调用或者复杂锁逻辑的情况下，Go的死锁检测可能不会触发。因此，即使Go运行时没有报告死锁，也不代表程序中不存在潜在的并发问题。
为了避免死锁，推荐的做法包括：
避免循环等待：设计系统时应确保资源的分配顺序一致，以避免循环等待的情况发生。 使用适当的同步原语：比如使用带缓冲的channel、正确使用锁（如sync.Mutex）、以及其他并发控制工具（如sync.WaitGroup、context.Context等）。 限制并发数：有时通过限制系统中并发执行的goroutine数量可以简化资源管理，减少死锁的风险。 彻底测试：并发程序应该经过详尽的测试，包括使用竞态检测工具（如Go的-race标志）来帮助识别并发错误。 这些措施可以帮助开发者构建更健壮、更可靠的并发程序。</description>
    </item>
    
    <item>
      <title>在docker模拟虚拟IP实验时遇到的问题</title>
      <link>https://shifengbin.github.io/posts/linux/docker_vip/</link>
      <pubDate>Fri, 26 Apr 2024 18:12:19 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/linux/docker_vip/</guid>
      <description>获取不到虚拟IP 使用下面的命令时不能获取到虚拟IP
docker run -it --net vipnet --ip 172.18.0.2 vipimage /bin/bash 应该添加参数可以让容器有权限操作网络配置
docker run -it --net vipnet --ip 172.18.0.2 --cap-add=NET_ADMIN vipimage /bin/bash 或者
docker run -it --net vipnet --ip 172.18.0.2 --privileged vipimage /bin/bash privileged小知识 在 Docker 中使用 --privileged 标志会给容器提供类似于宿主机 root 用户的权限。当容器以 --privileged 模式运行时，它可以绕过 Linux 内核的许多安全限制，从而获得较广泛的操作权限。这通常用于需要执行一些高级系统管理操作的场景，例如直接访问硬件设备或进行某些需要特殊权限的网络操作。
--privileged 模式的主要影响包括： 全能力（Capabilities）：
容器将获得 Linux 所有的 capabilities，与在宿主机上运行的进程几乎相同。 设备访问：
容器可以访问和操作宿主机上的所有设备（/dev 下的设备）。 安全限制：
绕过了 AppArmor 或 SELinux 的限制，容器可以执行更多的系统级操作。 文件系统：
容器可以挂载宿主机上的文件系统，甚至使用一些通常需要更高权限的挂载选项。 网络操作：
允许执行一些通常受限的网络操作，如更改网络配置或使用低号端口。 使用场景 使用 --privileged 模式通常适用于以下场景：
开发和测试：</description>
    </item>
    
    <item>
      <title>Wine</title>
      <link>https://shifengbin.github.io/posts/linux/wine/</link>
      <pubDate>Mon, 22 Apr 2024 16:42:34 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/linux/wine/</guid>
      <description>使用flatpak安装wine后执行winecfg配置wine时出现乱码可以使用命令安装字体解决
sudo apt-get install fonts-wqy-zenhei fonts-wqy-microhei </description>
    </item>
    
    <item>
      <title>添加字段引发的不兼容</title>
      <link>https://shifengbin.github.io/posts/db/add_filed/</link>
      <pubDate>Fri, 12 Jan 2024 12:37:19 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/db/add_filed/</guid>
      <description>大家都是知道如果我们在接口返回值添加字段或者proto中添加字段一般是不会发生不兼容的情况，那么在数据库中给表添加字段会导致不兼容问题吗？
通常情况是不会，添加字段不会影响到已有的数据，但是下面这种情况会引发不兼容
假设A表有字段id, bid, c, B表有id, d,业务中有这么一条语句
select a.id, b.d from a join b on a.bid = b.id where c = 1; 那么现在我们给B表加字段c,那么现在这个语句就会错，因为a表有个c,b表有个c,现在where条件中的c已经有歧义了，所以这条语句就会报错，所以给表加字段会引发不兼容
所以加字段的时候也要小心，sql如果是多表一定给字段加上别名，避免这种歧义就比如上面的语句就改为
select a.id, b.d from a join b on a.bid = b.id where a.c = 1; 这只能说约束我们自己，历史的老系统中有什么样的写法都未可知</description>
    </item>
    
    <item>
      <title>mysql中time_zone的作用，以及为什么要配置本地时区和db时区</title>
      <link>https://shifengbin.github.io/posts/go/go_mysql/</link>
      <pubDate>Mon, 11 Dec 2023 10:41:18 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go/go_mysql/</guid>
      <description>mysql中time_zone的作用，以及为什么要配置本地时区和db时区 1. mysql中time_zone的作用 mysql中time_zone的作用，就是用来设置时区的（废话），time_zone影响TIMESTAMP类型和NOW等函数的值，但并不影响DATETIME类型和DATE类型。
因为TIMESTAMP存储的时时间戳，当用户发送过来一个时间如“2023-12-11 10:41:18”，那么mysql会将其时间戳,这个时间就是按time_zone设置的时区来解析的，然后转换成时间戳保存，
在给用户查询时在通过时区转换会时间串。
DATETIME类型不是时间戳，存入时是“2023-12-11 10:41:18”，查询时也是“2023-12-11 10:41:18”，不会做转换，也和时区无关
2. 为什么要配置本地时区和db时区 本地时区是给mysql驱动使用，并不会影响mysql的时区，只会影响mysql驱动的解析，
db时区是mysql的时区，会影响mysql的时区，会影响mysql的查询结果。
本地时区作用 在读取到mysql发来的时间，go会按照本地时区来解析，转换为time.Time类型mysql按照数据库time_zone返回时间串后，go并不知道用哪个时区来解析这个时间串，所以需要设置本地时区。 本在写入time.Time类型时，go会把time.Time转换为本地时区发送给mysql 比如设置本地时区为“Asia/Shanghai” root:root@tcp(127.0.0.1:3306)/db?charset=utf8&amp;amp;loc=Asia%2FShanghai&amp;amp;parseTime=true通过loc参数来这设置
同时设置本地和数据库时区 root:root@tcp(127.0.0.1:3306)/db?charset=utf8&amp;amp;loc=Asia%2FShanghai&amp;amp;parseTime=true&amp;amp;time_zone=%27%2B8%3A00%27
dsn上的参数有的是给数据库驱动使用，有的是给mysql使用，具体可参阅mysql驱动的DSN</description>
    </item>
    
    <item>
      <title>本地&#43;redis多级缓存</title>
      <link>https://shifengbin.github.io/posts/micro_service/multi_cache/</link>
      <pubDate>Fri, 24 Nov 2023 14:20:35 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/micro_service/multi_cache/</guid>
      <description>由一次线上问题引发的思考，本地缓存+redis缓存的多级缓存方案。
一次线上发生OOM, CPU占用高排查，之前所有的缓存都是放在redis中，并发高时，大量请求去redis,服务反序列化，导致CPU占用高，内存占用高，最终达到资源上线被k8s杀掉。
后来想到了使用本地缓存，这种公共对象保存一份数据，不用反复序列化，减少CPU占用，减少内存占用，但是本地缓存有一个问题，多个副本在同一时间可能缓存数据不一致，虽然在我们这个场景下，这份公共数据更新不频繁，但是也有可能发生这个情况，所以想到了使用多级缓存，本地缓存+redis缓存，本地缓存作为一级缓存，redis作为二级缓存，当redis更新时会设置数据版本号(时间戳)，本地获取时会比对版本号，如果相同redis就不返回数据，如果不同就返回数据，这样就可以保证数据一致性。
用go描述一下取值和设置值的逻辑，其他逻辑都比较简单，这里使用lua脚本来实现，版本和数据的原子性和比较版本和返回相应的返回值，还可以减少网络开销
package main import ( &amp;#34;fmt&amp;#34; &amp;#34;time&amp;#34; &amp;#34;github.com/go-redis/redis&amp;#34; ) //这段脚本是用来设置值的，设置值的时候会设置版本号，设置过期时间 const setval = ` local key_val = KEYS[1] local key_version = key_val .. &amp;#34;_version&amp;#34; local val = ARGV[1] local expire = ARGV[2] local version = ARGV[3] redis.call(&amp;#39;SET&amp;#39;, key_version, version) redis.call(&amp;#39;EXPIRE&amp;#39;, key_version, expire) redis.call(&amp;#39;SET&amp;#39;, key_val, val) redis.call(&amp;#39;EXPIRE&amp;#39;, key_val, expire) return nil ` //这段脚本是用来取值的，取值的时候会比较版本号，如果版本号不一致就返回值 const getval = ` local key_val = KEYS[1] local key_version = key_val .. &amp;#34;_version&amp;#34; local givenVersion = ARGV[1] local version = redis.</description>
    </item>
    
    <item>
      <title>DCDC原理 电感</title>
      <link>https://shifengbin.github.io/posts/embed/dcdc-inductance/</link>
      <pubDate>Thu, 23 Nov 2023 14:42:12 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/embed/dcdc-inductance/</guid>
      <description>DCDC 升压原理 直流-直流（DC-DC）升压转换器是一种电子电路，用于将输入直流电压转换为较高的输出直流电压。其原理基于能量储存和传递的概念。
DC-DC升压转换器的基本原理： 开关器件： 这种转换器通常使用开关器件（如MOSFET）来控制输入电压的存储和传递。这些器件通过开关操作，控制能量流动的路径，实现电压转换。
储能元件： 其中一个核心组件是储能元件，比如电感或电容。在升压转换器中，电感是最常见的储能元件之一。当开关器件关闭时，电感储存电能；当开关器件打开时，储能元件释放储存的能量，以提供输出所需的较高电压。
控制电路： 升压转换器还包括一个控制电路，用于监测输出电压并控制开关器件的工作周期，以保持所需输出电压稳定。
脉宽调制（PWM）： 控制电路通常使用脉宽调制技术，通过改变开关器件的工作周期和频率来调节输出电压。通过调整开关器件的工作时间和间隔，可以控制能量传递的速率，从而实现输出电压的精确调节。
在升压转换器中，输入电压经过周期性开关，并通过储能元件转换为较高的输出电压。这种转换方式允许在电子设备中提供所需的不同电压，例如从电池供电的设备需要较高的工作电压。
总的来说，DC-DC升压转换器通过开关器件、储能元件和控制电路来转换输入电压为所需的更高输出电压，使得在各种应用中能够实现稳定的电源供应。
如何控制电感储能后的电压 控制电感储能后的电压通常通过调整开关器件的工作周期和频率来实现。这涉及到脉宽调制（PWM）技术，通过改变开关器件的导通和关断时间，控制能量的传递速率，从而调节输出电压。
以下是实现这种控制的基本步骤：
脉宽调制（PWM）： 使用PWM技术来调节开关器件的导通和关断时间。导通时间越长，电感中储存的能量就越多，从而提高输出电压。关断时间的调节则影响能量传递的速率。
控制电路： 设计一个控制电路，该电路监测输出电压并与设定值进行比较。根据比较的结果，调整PWM信号，以使输出电压保持在所需的水平。
反馈回路： 在控制电路中加入反馈回路，用于实时监测输出电压。一种常见的反馈方式是采用电压反馈，其中输出电压与参考电压进行比较，然后调整PWM信号以纠正任何电压偏差。
PID控制： 对于更复杂的系统，可能采用比例-积分-微分（PID）控制器。PID控制器可以更精确地调节输出电压，通过对比例项、积分项和微分项的权衡来实现快速而稳定的响应。
通过这些控制手段，可以实现对电感储能后的电压进行精确调节，使其保持在所需的水平，从而满足不同应用对电源电压的要求。
如何理解通过PWM来调节电感电压，举例说明 脉宽调制（PWM）是一种通过调整脉冲的宽度来控制平均电压的技术。在电感储能的情况下，PWM被用来调节开关器件的工作周期，从而影响电感中存储的能量量，最终调节输出电压。以下是一个简单的例子，说明如何通过PWM来调节电感电压：
基本电路架构： 考虑一个基本的升压DC-DC转换器，包含以下关键组件：
开关器件（例如MOSFET）：用于控制电能的开关。 电感：储存能量的元件。 控制电路：监测输出电压并生成PWM信号。
工作原理： 当开关器件导通（关闭）时，电流通过电感，将能量储存在电感中。 当开关器件关断时，储存在电感中的能量通过二极管传递到输出端，提供给负载。
PWM控制： 控制电路监测输出电压，并将其与设定值进行比较。 如果输出电压低于设定值，控制电路将增加PWM信号的宽度，延长开关器件的导通时间，使电感中储存的能量增加。 如果输出电压高于设定值，控制电路将减小PWM信号的宽度，缩短导通时间，减少电感中的储能。
示例： 初始状态下，输出电压低于设定值。 控制电路增加PWM信号的宽度。 开关器件导通时间延长，电感中储存的能量增加。 输出电压逐渐上升。 控制电路监测到输出电压接近设定值，减小PWM信号的宽度。 开关器件导通时间缩短，电感中的储能减少。 输出电压稳定在设定值附近。 通过这种方式，PWM信号的调节直接影响了开关器件的工作周期，从而影响了电感中储存的能量，最终调整了输出电压。这种反馈控制系统能够在不同工作条件下稳定地提供所需的电压输出。
如何计算通断时间产生的电感电压 电感在开关电路中的通断时间会影响其产生的电压。在直流-直流（DC-DC）升压转换器中，可以使用以下基本公式来估算电感电压：
$V_L = L \frac{\Delta I}{\Delta t}$
其中：
$(V_L)$ 是电感上的电压。
$(L)$ 是电感的电感值。
$(\Delta I)$ 是电感中电流的变化。
$(\Delta t)$ 是电流变化所经过的时间。
这个公式基于电感的电压-电流关系：
$V_L = L \frac{di}{dt}$</description>
    </item>
    
    <item>
      <title>Viper读取自定义远程配置</title>
      <link>https://shifengbin.github.io/posts/go/viper/</link>
      <pubDate>Fri, 15 Sep 2023 15:56:44 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go/viper/</guid>
      <description>实现viper.remoteConfigFactory接口 type remoteConfigProvider struct{} //这个接口是在第一次读取远程配置时调用，viper.ReadRemoteConfig() func (rc remoteConfigProvider) Get(rp viper.RemoteProvider) (io.Reader, error) { log.Println(&amp;#34;Getting config from remote&amp;#34;, rp) r := bytes.NewReader([]byte(&amp;#34;{\&amp;#34;a\&amp;#34;:1}&amp;#34;)) time.Sleep(time.Second) return r, nil } //这个接口是在客户端调用viper.WatchRemoteConfig()， 只监听一次变化 func (rc remoteConfigProvider) Watch(rp viper.RemoteProvider) (io.Reader, error) { //这里写你获取配置的方法 log.Println(&amp;#34;Watching config from remote&amp;#34;, rp) s := fmt.Sprintf(`{&amp;#34;app&amp;#34;:{&amp;#34;name&amp;#34;:&amp;#34;test&amp;#34;,&amp;#34;version&amp;#34;:%d}}`, time.Now().Unix()) r := bytes.NewReader([]byte(s)) time.Sleep(time.Second) return r, nil } //这个接口是在客户端调用viper.GetViper().WatchRemoteConfigOnChannel()时，监听多次变化 func (rc remoteConfigProvider) WatchChannel(rp viper.RemoteProvider) (&amp;lt;-chan *viper.RemoteResponse, chan bool) { log.Println(&amp;#34;Watching Channel config from remote&amp;#34;, rp) ch := make(chan *viper.</description>
    </item>
    
    <item>
      <title>在docker中go编译应注意的问题</title>
      <link>https://shifengbin.github.io/posts/go/docker/</link>
      <pubDate>Thu, 07 Sep 2023 11:17:42 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go/docker/</guid>
      <description>1.使用golang:tag 这种镜像编译后在alpine中会报错(not found) 原因是：go默认会使用glibc,而alpine中没有glibc,所以会报错 解决办法有三种： 连接RUN mkdir /lib64 &amp;amp;&amp;amp; ln -s /lib/libc.musl-x86_64.so.1 /lib64/ld-linux-x86_64.so.2，建立一个glic链接 使用golang:tag-alpine镜像编译，编译系统和运行系统都用alpine 编译时禁用CGO CGO_ENABLED=0 go build编译出来的文件不依赖动态库 </description>
    </item>
    
    <item>
      <title>Ubuntu当开发过程中主力机遇到的问题</title>
      <link>https://shifengbin.github.io/posts/linux/qa/</link>
      <pubDate>Mon, 14 Aug 2023 15:08:46 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/linux/qa/</guid>
      <description>使用deb包安装软件时想要拆卸 在使用dpkg -r拆卸软件需要知道包名，有的时候不好查，可以使用用Ubuntu Software打开deb包，点删除
安装virtualbox,启动虚拟机报 Kernel driver not installed (rc=-1908) 可以使用sudo apt install --reinstall linux-headers-$(uname -r) virtualbox-dkms dkms 安装完成后重启
使用clash for window时，无法正常代理 在ubuntu设置中，点击网络，设置网络代理配置好即可
使用拼音输入法 安装fcitx5
sudo apt install fcitx5 \ fcitx5-chinese-addons \ fcitx5-frontend-gtk4 fcitx5-frontend-gtk3 fcitx5-frontend-gtk2 \ fcitx5-frontend-qt5 安装词库
在https://github.com/felixonmars/fcitx5-pinyin-zhwiki/releases下载.dict结尾的词库文件，放入 ~/.local/share/fcitx5/pinyin/dictionaries/，没有创建即可。
设置默认输入法im-config命令
配置环境变量/etc/profile
export XMODIFIERS=@im=fcitx export GTK_IM_MODULE=fcitx export QT_IM_MODULE=fcitx 在home目录.pam_environment添加配置
GTK_IM_MODULE DEFAULT=fcitx QT_IM_MODULE DEFAULT=fcitx XMODIFIERS DEFAULT=@im=fcitx SDL_IM_MODULE DEFAULT=fcitx 非root用户无法使用80端口 通过执行sudo sysctl -w net.ipv4.ip_unprivileged_port_start=80命令，你在更改了系统配置文件，指定了非特权用户可以使用的TCP/UDP端口号的起始值为80。这意味着普通用户可以绑定和使用80端口，而无需特权身份（如root或管理员权限）。
不过这样重启后就无法使用80端口了，所以需要配置一个重启后也生效的配置文件，打开/etc/sysctl.conf文件，在文件后面追加 net.ipv4.ip_unprivileged_port_start = 80，这样重启后也可以生效。</description>
    </item>
    
    <item>
      <title>内存泄漏</title>
      <link>https://shifengbin.github.io/posts/go/memory_leak/</link>
      <pubDate>Thu, 03 Aug 2023 09:57:26 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go/memory_leak/</guid>
      <description>因一次线上内存泄漏问题的总结
go 内存泄漏大概有一下几种情况
长期存活的对象：如果某些对象的生命周期较长，但在使用完之后没有被正确释放，这些对象将一直保留在内存中，导致内存泄漏。
协程泄漏：在 Go 中，每个协程（goroutine）都是轻量级的并发执行单元。如果你启动了太多的协程并且没有适时关闭或终止它们，那么这些协程就会一直存在并占用内存，导致内存泄漏。
循环引用：如果存在对象之间的循环引用关系，即两个或多个对象相互引用，而没有其他的引用指向它们，这将阻止垃圾回收器回收这些对象，导致内存泄漏。
意外的全局变量引用：如果你在函数中意外保留了对全局变量的引用，即使函数执行完毕，这个函数所涉及的内存也无法释放，导致内存泄漏。
未关闭的文件或网络连接：如果在读写文件、网络通信或数据库连接等操作后，忘记关闭这些资源，将会导致系统资源泄漏，最终影响内存的使用。
不正确的缓存管理：当使用缓存来存储数据时，如果没有合适地管理缓存的大小和生命周期，可能会导致过多的对象一直存在于缓存中而无法被释放，从而引发内存泄漏。
未正确使用释放资源的函数：在使用第三方库或 API 时，如果没有按照正确的方式使用和释放资源，比如数据库连接或操作系统句柄等，将导致资源泄漏，可能会间接导致内存泄漏。
这次出问题的是未关闭网络连接(集群内其他服务)没有关闭http Response.Body,导致这两个程序内存一直增长,一个服务内存泄漏导致另一个服务goroutine无法释放,到达k8s内存上限被kill掉
排查方法
通过代码pprof抓取相应数据 导入net/http/pprof自动注册内置好的处理方法,开启默认http服务 我们主要看第二种,第一种可以自己看net/http/pprof里面的写法或者参考文档
用浏览器查看http[s]://xxx/debug/pprof页面,一共有如下几个指标
allocs: 内存过往统计,可以看运行过程中哪些过程使用内存最多 block: 看有哪些被阻塞了,比如各种io cmdline: 运行程序时的名称和参数 比如`./app a b c` goroutine: goroutine信息 heap: 在用堆内存信息 mutex: 锁信息 profile: CPU信息 threadcreate: 系统线程创建信息 trace: 追踪信息,比如GC, 各个goroutine调度等 其中allocs/block/goroutine/heap/mutex/profile 都可以使用go tool pprof -http=&amp;quot;:8080&amp;quot; http[s]://host:port/debug/pprof/xxxxx(其中xxxxx用前面几种指标代替) 查看详细信息
trace需要先点击trace下载,然后使用go tool trace tracefile来查看</description>
    </item>
    
    <item>
      <title>51单片机注意事项</title>
      <link>https://shifengbin.github.io/posts/embed/51/</link>
      <pubDate>Thu, 27 Jul 2023 16:14:07 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/embed/51/</guid>
      <description>下面的51均指的是STC89C52RC芯片,别的51是否也是这样有待验证
io相关注意事项 51在读取io时需要设置io口为高电平,然后再读取 8051（包括 STC89C52RC）的 I/O 口是开漏（open-drain）输出而非推挽（push-pull）输出。
开漏输出只能主动驱动低电平（0），不能主动驱动高电平（1）。要实现高电平，开漏输出需要通过外部的拉升电阻（通常连接到电源 VCC）实现。这也就是为什么在使用开漏输出的 GPIO 引脚时，你需要首先将它设置为高电平，然后才可以正确读取输入的低电平。
相比之下，推挽输出可以主动驱动低电平和高电平。这就使得在使用推挽输出时，不需要首先设定为高电平来正确读取低电平。
这就是为什么你在使用 STC89C52RC 或者其他 8051 系列的微控制器时，必须首先将引脚设为高电平，只有这样，你才能正确地读取被设为低电平的输入。因此，理解开漏和推挽输出的区别对于理解这个问题是非常重要的。每种类型的输出方式都有其优缺点，需要根据具体应用来选择。
内置EEPROM 在写入前需要先擦除 原因是内部的EEPROM是用Flash来做的,由于Flash的物理性质,只能从1变0,不能从0变1,所以先要擦除为0xFF, 然后在写入相应的数据,注意擦除是按扇区来擦除的
Flash存储器使用了浮动栅层的原理来存储数据，在晶体管中存储了电荷量，代表了0或1的状态。当需要将存储单元从1改为0时，可以通过施加适当的电压，将电荷从浮动栅层中移除，使得晶体管的导通特性被改变为阻断状态，表示0。
然而，将存储单元从0改为1是不可行的，因为在Flash存储器中，写入操作是通过电子隧穿来实现的。当试图将存储单元从0改为1时，需要将电子引入浮动栅层。但是，由于浮动栅层与控制栅层之间的绝缘层，电子无法通过正常的电子隧穿过程引入到浮动栅层中，因此无法实现将0写成1的操作。
为了将存储单元从0改为1，需要执行擦除操作。擦除会将整个存储单元中的电荷移除，将其重置为初始状态，通常是全1。然后再通过编程操作将所需的位写入为1。
由于擦除操作会擦除整个存储单元的数据，而不是单个位或字节，因此对Flash存储器进行写入操作时，通常需要将整个存储块或页擦除，然后再编程所需的位。这种擦除和编程的特性使得Flash存储器在数据写入方面有一定的限制和特殊性。
LCD1602异常 是否是每个阶段的延迟不够 调高延迟试一下是否正常
多写一些字符 如果出现屏幕位置不同,可能是算法问题
乱码(比如全屏写&#39;1&amp;rsquo;,但是显示的是其他内容) 可能是虚焊
判断方法:
写一个程序,使io口高低电平切换,如果使用示波器可以间隔短点间隔时间, 如果使用万用表让间隔长一点比如5s切换一次电平 使用示波器或者万用表分别测量每个io对应的LCD接口,看是否有电平切换, 可以判断接口是否异常 再看芯片对应异常的io引脚如果输出是正常,则说明虚焊,如果引脚输出异常,则可能是芯片坏了 </description>
    </item>
    
    <item>
      <title>三极管集电极电流产生原理</title>
      <link>https://shifengbin.github.io/posts/embed/bjt/</link>
      <pubDate>Wed, 19 Jul 2023 16:43:28 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/embed/bjt/</guid>
      <description>三极管作为一种重要的半导体器件,其集电结反向偏置时表现出的导电性违背了PN结的传统认知,这一现象的原因一直令人感到好奇。在本文中,笔者将通俗解释三极管反向偏置下集电结仍可导电的科学机理。
我们知道,PN结反向偏置时,少数载流子形成的漏电流非常微弱。但三极管的情况则完全不同,反向偏置的集电结也会产生明显的集电电流Ic。这主要归因于三极管独特的内部结构。
需要强调的是,这种反向偏置下的电流并非由反向击穿产生,而是有别于PN结的全新机理。三极管通过基极控制发射极附近的电子浓度。当基极电流注入电子时,发射极区域会聚集大量电子。这些电子可以跨越集电结的反向势垒,形成显著的反向漏电流。随着基极电流增大,发射极电子浓度提高,反向漏电流Ic也随之增加。
可以看出,三极管反向偏置下集电结的导电性,是由基极注入产生的大量电子引起的。这种机理完全不同于PN结中仅依赖少数载流子的反向漏电流。正是三极管的独特结构及工作原理导致了反向偏置下也存在明显Ic的现象。
值得注意的是,PN结在正向偏置时,电流主要由多数载流子形成;而反向偏置时,则由少数载流子形成微弱的电流。三极管反向偏置下Ic的产生,则利用了基极注入的大量电子,从电流形成机理上破除了PN结的限制。
通过解析三极管反向偏置导通的科学机理,我们加深了对其工作原理的理解。这也展示了半导体器件的奥秘比单纯PN结更为复杂。希望本文能够满足读者对这个有趣现象的好奇心,并成为理解半导体物理的一个窗口。
注意: 在严格意义上说PN并不能单向导电,我们所说的单向导电只是因为反向电流非常微弱 PN结在正向偏置时,电流主要由多数载流子形成;而反向偏置时,则由少数载流子形成微弱的电流</description>
    </item>
    
    <item>
      <title>复位电路电容选择</title>
      <link>https://shifengbin.github.io/posts/embed/reset/</link>
      <pubDate>Thu, 08 Jun 2023 11:06:21 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/embed/reset/</guid>
      <description>${T = R C}$ 变换为 ${C = \frac T R }$ 其中T为时间 R为电阻 C为电容
以1ms复位时间来算, 如果电阻选10kΩ那么 $C = \frac {0.001s} {10000Ω} = 100nF$</description>
    </item>
    
    <item>
      <title>外部中断和定时器</title>
      <link>https://shifengbin.github.io/posts/embed/interrupt/</link>
      <pubDate>Tue, 06 Jun 2023 11:09:27 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/embed/interrupt/</guid>
      <description>都说学习硬件是学习计算机组成原理的快速途径,我也入坑了,这里记录一些学习中初学者可能感觉难受的难点
一个MCU就好比一个很复杂的函数,他需要两种初始化,一种就是硬件初始化(也就是最小系统+外设电路), 一种是软件初始化(设置寄存器来使用某些功能)
中断 其实也没什么难的,难的是和GPIO那种简单方式的对比,都是固定套路
中断套路 编写好中断处理函数 设置触发方式(低电平触发或者下降沿触发) 开启某一中断 开启总中断 定时器 套路 设置定时器模式 设置定时器初值 开启定时器 (到目前定时器已经可以使用了) 定时器中断开启 (如果还想定时中断的话,需要剩下3,4两步) 总中断开启 中断优先级可以进行调整</description>
    </item>
    
    <item>
      <title>数据库中排序的一些想法</title>
      <link>https://shifengbin.github.io/posts/math/sort/</link>
      <pubDate>Fri, 02 Jun 2023 10:18:35 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/math/sort/</guid>
      <description>数据库中很多时候要有排序字段作为排序依据,有时候还会对排序进行调整,常见的我们会加一个xx_sort字段,从1开始的一个排序,那样如果我们把最后一个元素排到第一时会导致每个记录中排序都要进行+1操作,需要操作很多记录;那有没有一种方法可以只修改被调整的那一条记录或者减少更改记录的次数.
今天想到一个方法,在给排序字段赋值的时候,不是按照+1的方式递增,而是以一个间隔递增比如
id order 1 1 2 1001 3 2001 4 3001 在每次调整顺序时,比如把4调整到1和2之间, 那么就在(1,1001)区间范围内随机找到一个值(或者取中间值),赋给4这种情况下只需要调整一次就可以了.
那么如果上面的结果变成这样了, 3想要移动到1和4之间怎么办
id order 1 1 4 2 2 1001 3 2001 和上面一样现在(1,2)区间随机(或者取中间值),发现不能找到一个值,那么就需要一个策略,把后面的一部分数据进行分散.
分散策略比如:按顺序找到后面一条间距大于多少的(比如1000)数据,然后把这几条数据按总间距平均分配一下,或者更简单粗暴的,如果遇到无法插入的值,就把后面的数据重新安排一下,都按初始间隔重新赋值
只要合理的设置间隔,就能达到在大多数情况下都能只修改一条记录
注意: 设置间隔可能需要考虑最多能容纳多少元素,还有字段类型所能容纳的最大值</description>
    </item>
    
    <item>
      <title>service中的几种port的区别</title>
      <link>https://shifengbin.github.io/posts/k8s/service_ports/</link>
      <pubDate>Mon, 22 May 2023 15:00:31 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/k8s/service_ports/</guid>
      <description> port : service暴露的端口,可以在集群内进行访问 nodePort : 可以在集群外访问service的端口 targetPort : pod内的container暴露的端口 一张图来理解 </description>
    </item>
    
    <item>
      <title>k8s 几种探针作用和用法</title>
      <link>https://shifengbin.github.io/posts/k8s/probs/</link>
      <pubDate>Fri, 12 May 2023 11:03:18 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/k8s/probs/</guid>
      <description>在 Kubernetes 中，探针（probes）是一种机制，用于检查容器是否处于正常状态以及容器是否可以接收流量。 Kubernetes 提供了三种类型的探针：存活探针（Liveness Probe）、就绪探针（Readiness Probe）和启动探针（Startup Probe）。
以下是这三种探针的作用和用法：
存活探针（Liveness Probe） 作用：检查容器中的进程是否仍在运行。如果进程崩溃或停止响应，Kubernetes 将重启容器。 用法：建议在容器的生命周期中始终使用存活探针，以确保容器的可靠性。例如，您可以配置一个存活探针来检查容器中的进程是否响应 HTTP 请求或 ping 命令。
示例 YAML 配置：
livenessProbe: httpGet: path: /healthz port: 8080 initialDelaySeconds: 5 periodSeconds: 10 该配置文件指示 Kubernetes 发送一个 HTTP GET 请求到容器的 /healthz 路径，并在容器启动后的 5 秒后开始检查容器的运行状况。检查频率为每隔 10 秒发送一次。
就绪探针（Readiness Probe） 作用：检查容器是否准备好接收流量。如果容器尚未准备好接收流量，则 Kubernetes 将不会将流量发送到容器。 用法：建议在容器需要一些额外的时间来启动的情况下使用就绪探针。例如，您可以配置一个就绪探针来检查容器是否存在必需的文件或数据库连接。
示例 YAML 配置：
readinessProbe: tcpSocket: port: 8080 initialDelaySeconds: 5 periodSeconds: 10 该配置文件指示 Kubernetes 检查容器是否可以在 8080 端口接收 TCP 连接，并在容器启动后的 5 秒后开始检查容器的运行状况。检查频率为每隔 10 秒发送一次。</description>
    </item>
    
    <item>
      <title>在WSL中配置gitlab/github SSH KEY</title>
      <link>https://shifengbin.github.io/posts/git/auth/</link>
      <pubDate>Mon, 08 May 2023 14:24:08 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/git/auth/</guid>
      <description>背景 在公司里普遍使用搭建的gitlab,很多情况下我们使用终端提交,这时候就会频繁的数据账户和密码,为了不输入密码我们会配置SSH KEY来免登录.
步骤 使用ssh-keygen 来生成公钥和私钥 使用ssh-keygen -t ed25519 或者 ssh-keygen -t rsa -b 2048 没什么特别的一路回车 这时候会在你~/.ssh/目录下生成密钥对 以rsa密钥为例,把~/.ssh/id_rsa.pub的内容配置到gitlab 测试使用ssh git@gitlab.xxx.com(你公司的域名)看下是否正常打印你的配置名称,如果不正常使用ssh -Tvvv git@gitlab.xxx.com打印调试信息,看是哪个地方出了问题 已经可以正常提交代码 可能出现的问题 ssh连接没问题,但是git会提示输入用户密码 这种情况看下自己仓库是否使用的是http连接, 如果是替换ssh链接就可以解决git remote set-url origin git@xxx.com:username/blog.git
使用go来拉取包时如果使用http地址拉取怎么办 可以使用Git提供的凭证存储器来配置HTTP协议的自动登录,Git提供了三种凭证存储器，分别是cache、store和osxkeychain。不同的存储器有各自的优缺点，例如cache存储器将凭证信息保存在内存中，store存储器将凭证信息保存在本地的plain-text文件中，osxkeychain存储器则将凭证信息保存到Mac的Keychain应用程序中.
可以使用git config --global credential.helper store来配置,然后随便拉取一个该域名的项目,输入账号密码就会存储到本地,后面就不会再要求输入用户密码</description>
    </item>
    
    <item>
      <title>go 编译指令build</title>
      <link>https://shifengbin.github.io/posts/go/build/</link>
      <pubDate>Tue, 07 Mar 2023 10:50:47 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go/build/</guid>
      <description>go:build 是 Go 1.17 版本中引入的一个构建标记，用于根据不同的条件控制代码的编译。go:build 格式如//go:build &amp;lt;标记表达式&amp;gt;, 1.17之前使用+build的方式,这里我们介绍更强大的的go:build.
表达式可以包含由 ||、&amp;amp;&amp;amp; 和 ! 运算符和括号组合的选项,含义与 Go 语言中相同.
构建约束可以出现在任何类型的源文件中（不仅仅是 Go 文件），但是它们必须出现在文件的顶部附近，仅由空行和其他行注释分隔。这些规则意味着在 Go 文件中，构建约束必须出现在包声明之前。
例如，下面的构建约束将约束一个文件在满足“linux”和“386”约束条件或在满足“darwin”条件且未满足“cgo”条件时进行构建：//go:build (linux &amp;amp;&amp;amp; 386) || (darwin &amp;amp;&amp;amp; !cgo)
自定义tag
//go:build atest
当我们使用go build -tags atest的情况下会编译此文件,否则不会编译
控制go版本
//go:build go1.17 指定当前文件&amp;gt;=go1.17才编译
//go:build go1.17 &amp;amp;&amp;amp; go1.20 版本&amp;gt;= go1.17 并且&amp;lt;= go1.20</description>
    </item>
    
    <item>
      <title>Intel hex文件格式</title>
      <link>https://shifengbin.github.io/posts/hd/intel_hex/</link>
      <pubDate>Mon, 27 Feb 2023 16:45:45 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/hd/intel_hex/</guid>
      <description>Intel HEX格式文件是一种常见的用于表示程序存储器内容的文本格式，常用于将程序存储器内容导出或者导入到不同的开发工具中。它的文件扩展名通常是 .hex。
该文件格式由一系列行组成，每一行以冒号(:)开头，以回车换行符(\r\n)结尾，每一行包含以下几个部分：
起始符号：一个字符，表示该行的起始，必须为“:”。
数据长度：一个字节，表示该行所包含的数据长度，以字节为单位，范围从 0 到 255。
起始地址：两个字节，表示该行数据在存储器中的起始地址，以字节为单位，高位在前，低位在后。
记录类型：一个字节，表示该行数据的类型。常见的记录类型包括数据记录（00）、结束记录（01）等。
数据：一个或多个字节，表示该行的数据内容。数据的长度由数据长度字段指定。
校验和：一个字节，表示该行数据的校验和，为数据长度、起始地址、记录类型和数据的按位异或和的补码。
例如
:10010000214601360121470136007EFE09D2190140 //起始符号是“:”。 //数据长度是“10”。 //起始地址是“0100”。 //记录类型是“00”，表示这是一个数据记录。 //数据部分包含了16个字节的数据：“214601360121470136007EFE09D21901”。 //校验和是“40”。 //这个数据记录包含了16个字节的数据，它们对应的起始地址是0x0100~0x010F。每两个字节表示一个数据，因此这个记录实际包含了8个数据，分别是“21 46 01 36 01 21 47 01 36 00 7E FE 09 D2 19 01”。 :00000001FF //起始符号是“:”。 //数据长度是“00”。 //起始地址是“0000”。 //记录类型是“01”，表示这是一个结束记录。 //数据部分为空。 //校验和是“FF”。 //这个记录表示文件结束。当解析Intel HEX格式文件时，如果读到了一个记录类型为“01”的记录，就表示已经读到了文件的结尾，应该停止解析。 记录类型 在Intel HEX格式文件中，一共定义了5种记录类型。它们分别是：
数据记录（Data Record），记录类型为“00”。
结束记录（End Of File Record），记录类型为“01”。
扩展段地址记录（Extended Segment Address Record），记录类型为“02”。
扩展线性地址记录（Extended Linear Address Record），记录类型为“04”。
起始段地址记录（Start Segment Address Record），记录类型为“03”。 其中，最常用的是数据记录和结束记录。其他三种记录类型则用于更高级的应用，如程序跳转、内存分段等。
举例:
数据记录（Data Record）：:10010000214601360121470136007EFE09D2190140 这是一条16字节的数据记录，其记录类型为“00”。数据部分为“214601360121470136007EFE09D21901”。</description>
    </item>
    
    <item>
      <title>go 编译指令Linkname</title>
      <link>https://shifengbin.github.io/posts/go/linkname/</link>
      <pubDate>Fri, 24 Feb 2023 14:35:25 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go/linkname/</guid>
      <description>go:linkename是go的编译指令,可以在一个包中使用另一个包中的非导出函数或变量
具体使用方法举例
在pkg1包中有个未导出的函数add
package pkg1 func add(a, b int) int { return a + b } 在pkg2中想要使用pkg1.add,正常来说add开头是小写是不能被另一个包使用的,这时候我们想要在另一个包中使用就有两种方法:
在pkg1中定义一个可以导出的函数,这种就是在写个Add函数包裹一下,这种就不举例了 在pkg2中使用linkname编译指令修改函数或变量的名称和可见性(不太建议) 这里我们举例第二种
package pkg2 import ( _ &amp;#34;goasm/pkg1&amp;#34; //需要引入pkg1, 让pkg1参与代码编译,否则编译器找不到, 这句也可以写在别的文件中,只要让pkg1参与编译就行, relocation target goasm/pkg1.add not defined _ &amp;#34;unsafe&amp;#34; //编译器要求导入unsafe包,否则不能使用linkname指令 ) //下面就是linkname编译指令使用方法, 在函数声明上添加注释, 其中pkg1_add是函数名称, goasm/pkg1.add 是要连接的函数, 这句指令的效果就是,调用pkg1_add就是在调用goasm/pkg1包中的add函数 //go:linkname pkg1_add goasm/pkg1.add func pkg1_add(a, b int) int func Add2(a, b int) int { return pkg1_add(a, b) } 总结: go:linkname的使用是依赖于编译器的实现，因此使用时需要慎重考虑其可维护性和可移植性。 总之了解就好,不是迫不得已不要真的使用</description>
    </item>
    
    <item>
      <title>Swap开启和关闭</title>
      <link>https://shifengbin.github.io/posts/k8s/swap/</link>
      <pubDate>Thu, 23 Feb 2023 15:37:31 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/k8s/swap/</guid>
      <description>树莓派 /etc/dphys-swapfile 是 Raspberry Pi 上的一个文件，用于控制swap文件的设置和使用。该文件用于设置swap文件的大小、位置以及启用和禁用swap。
在 Raspberry Pi 上，如果想要使用swap文件，可以通过以下步骤配置和使用swap文件：
安装 dphys-swapfile 包，使用命令： sudo apt-get update sudo apt-get install dphys-swapfile 打开 /etc/dphys-swapfile 文件，配置swap文件的大小和位置。例如，将以下行： CONF_SWAPSIZE=100 #修改为0可关闭swap CONF_SWAPFILE=/var/swap 启用 sudo dphys-swapfile setup sudo dphys-swapfile swapon 禁用 sudo dphys-swapfile swapoff 其他linux 在Linux中，可以通过以下步骤关闭swap：
查看当前的swap情况，使用命令： swapon -s 如果没有任何输出，则说明当前系统没有启用swap。
如果系统启用了swap，需要先关闭swap，使用命令： swapoff -a 执行此命令会关闭所有swap分区。
临时禁用swap，使用命令： echo 0 &amp;gt; /proc/sys/vm/swappiness 执行此命令可以临时禁用swap，即使系统启用了swap，也不会自动将数据交换到swap分区。
永久禁用swap，可以修改/etc/fstab文件，注释掉swap分区的行，或者直接删除swap分区的行。例如，将以下行： #/dev/sda2 swap swap defaults 0 0 </description>
    </item>
    
    <item>
      <title>针对循环查询的逻辑优化思路</title>
      <link>https://shifengbin.github.io/posts/optimization/logic/</link>
      <pubDate>Thu, 02 Feb 2023 17:06:48 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/optimization/logic/</guid>
      <description>在工作中总能碰见有人的接口使用循环查询数据库的情况,针对这种情况我总结了一些针对这种情况的初步优化思路.
限制和优点 限制 此种方法只针对循环查询这种类型的优化
优点 不用完全了解业务逻辑,即可完成有效的优化
方法 概述 先明确循环的位置, 以及循环内要查的数据 采用包一层的思路(计算机界没有什么是包一层不能解决的, 如果不能就再包一层😊), 把查询提前到循环外, 通过提供相同的查询逻辑(在内存里的查询),替换循环中的查询(数据库的查询),必须保证新的查询和老查询功能一致. 听起来好像没什么特别的,我们来看下具体实施过程
伪代码 假设有一个这种函数
func GetPersonList(xx) { ps := models.GetPersonByXX() for _, v := range ps { //xxxx很多逻辑,很复杂 orders := models.GetOrderByPerson(v.ID) //这里循环查数据库,我们需要看懂这块的查询条件和返回值 //xxx很多逻辑,很复杂 } } 我们可以这样优化
//1. 在models层实现一个批量查询接口 models.GetOrderByPersons(id ...int) //2. 包一层实现一个数据缓存结构 type OrderDataCache struct { order map[int/*person id */] []Order //这里的结构根据具体查询定义, 上述例子是通过person id查 } //3. 初始化数据缓存结构函数, 根据你具体的业务实现 func NewOrderDataCache(personID ....int) OrderDataCache { //调用批量查询 orders := models.GetOrderByPersons(id .</description>
    </item>
    
    <item>
      <title>Proto Plugin</title>
      <link>https://shifengbin.github.io/posts/micro_service/proto_plugin/</link>
      <pubDate>Wed, 19 Oct 2022 11:39:19 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/micro_service/proto_plugin/</guid>
      <description>1.插件命名规则 ​ proto插件名称需要使用protoc-gen-xxx
​ 当使用protoc &amp;ndash;xxx_out时就会调用proto-gen-xxx插件
2.protobuf解析一般流程 方法1: 先通过标准输入生成CodeGeneratorRequest 通过CodeGeneratorRequest初始化插件plugin 通过插件plugin获取文件File 遍历文件,处理内容,生成文件 像标准输出写入响应plugin.Response 示例代码:
s := flag.String(&amp;#34;a&amp;#34;, &amp;#34;&amp;#34;, &amp;#34;a&amp;#34;) flag.Parse() //生成Request input, _ := ioutil.ReadAll(os.Stdin) var req pluginpb.CodeGeneratorRequest proto.Unmarshal(input, &amp;amp;req) //设置参数,生成plugin opts := protogen.Options{ ParamFunc: flag.CommandLine.Set, } plugin, err := opts.New(&amp;amp;req) if err != nil { panic(err) } fmt.Fprintf(os.Stderr, &amp;#34;a=%s\n&amp;#34;, *s) // protoc 将一组文件结构传递给程序处理,包含proto中import中的文件 for _, file := range plugin.Files { if !file.Generate { //显示传入的文件为true continue } fmt.Fprintf(os.Stderr, &amp;#34;path:%s\n&amp;#34;, file.GoImportPath) genF := plugin.</description>
    </item>
    
    <item>
      <title>树莓派安装k8s</title>
      <link>https://shifengbin.github.io/posts/k8s/k8s/</link>
      <pubDate>Wed, 05 Oct 2022 20:49:13 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/k8s/k8s/</guid>
      <description>本地系统为树莓派官方64位系统 Raspberry Pi OS Lite 64(Debian GNU/Linux 11)
在master和node都需要执行的步骤 本机cgroup配置 在执行kubeadm init 时出现 missing required cgroup: memory时,可以在/boot/cmdline.txt(有的系统可能在/boot/firmware/cmdline.txt)中追加 cgroup_enable=memory cgroup_memory=1
cgroup_enable=memory: 启用Cgroup子系统中的内存控制 cgroup_memory=1: 将内存控制子系统的版本设置为1
在某些特定的发行版中，可能会出于兼容性或其他原因而禁用了Cgroup子系统中的内存控制功能,所以需要手动开启
关闭swap 网上很多教程通过编辑/etc/fstab编辑swap, 但是在树莓派系统中,并不使用fstab配置,正确的做法是
编辑/etc/dphys-swapfile 找到配置项CONF_SWAPSIZE (通过名称我们可以知道该配置项为swap大小)该值配置为0 使配置生效 sudo /etc/init.d/dphys-swapfile restart 或者 sudo reboot 重启 通过free -h命令查看swap大小
系统模块加载 # 必要的模块加载 # overlay 文件系统 # br_netfilter 网桥网络包过滤 cat &amp;lt;&amp;lt;EOF | sudo tee /etc/modules-load.d/k8s.conf overlay br_netfilter EOF # 这个命令会将 &amp;#34;overlay&amp;#34; 和 &amp;#34;br_netfilter&amp;#34; 内核模块的名称添加到 /etc/modules-load.d/k8s.conf 文件中，以便在系统启动时自动加载这些模块 sudo modprobe overlay sudo modprobe br_netfilter # sudo modprobe overlay：加载 overlay 的内核模块，该模块提供了用于 overlayfs 的文件系统类型。在使用容器化技术如 Docker 时，通常需要使用 overlayfs 进行容器镜像的存储和管理。因此，在启用容器化环境时，需要确保该模块已加载。 # sudo modprobe br_netfilter：加载 br_netfilter 的内核模块，该模块提供了用于 Linux 桥接网络的过滤和 NAT 功能。在使用 Kubernetes 集群时，通常需要将容器内部的网络流量转发到主机上的网络设备，以实现容器与外部网络的通信。因此，在启用 Kubernetes 集群时，需要确保该模块已加载。 # 开启转发和流量可观测(开机启动) # sysctl params required by setup, params persist across reboots # bridge-nf-call-iptables 让ip表可以看到桥接流量 # bridge-nf-call-ip6tables 让ip6表可以看到桥接流量 cat &amp;lt;&amp;lt;EOF | sudo tee /etc/sysctl.</description>
    </item>
    
    <item>
      <title>树莓派系统关闭swap</title>
      <link>https://shifengbin.github.io/posts/pi/swap/</link>
      <pubDate>Sun, 02 Oct 2022 21:10:36 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/pi/swap/</guid>
      <description>网上很多教程通过编辑/etc/fstab编辑swap, 但是在树莓派系统中,并不使用fstab配置,正确的做法是
编辑/etc/dphys-swapfile 找到配置项CONF_SWAPSIZE (通过名称我们可以知道该配置项为swap大小)该值配置为0 使配置生效 sudo /etc/init.d/dphys-swapfile restart 或者 sudo reboot 重启 通过free -h命令查看swap大小</description>
    </item>
    
    <item>
      <title>Qemu&#43;gdb裸机调试</title>
      <link>https://shifengbin.github.io/posts/os/qemu_gdb/</link>
      <pubDate>Fri, 23 Sep 2022 16:31:24 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/os/qemu_gdb/</guid>
      <description>假设我们有一个boot.bin裸机汇编程序 我们想用qemu进行调试
我们可以使用qemu-system-x86_64 -s -S boot.bin
参数说明:
-s 可以使qemu开启1234端口,方便我们使用gdb连接调试
-S 可以让qemu暂停执行,等待我们使用gdb发送调试命令
gdb 连接:
使用gdb命令,进入gdb后使用target remote 127.0.0.1:1234连接到qemu</description>
    </item>
    
    <item>
      <title>errgroup</title>
      <link>https://shifengbin.github.io/posts/go_source/errgroup/</link>
      <pubDate>Tue, 06 Sep 2022 17:22:20 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go_source/errgroup/</guid>
      <description>errgroup是一个很简单的工具包,总共代码量加上注释和空行才100来行
作用就是方便执行的任务,比如
g := errgroup.Group{} g.Go(func1) g.Go(func2) if err := g.Wait(); err != nil { //... } 结构
type Group struct { cancel func() //context 取消函数 wg sync.WaitGroup //用来等待全部执行完成 sem chan token //用来控制并发数 errOnce sync.Once //控制err字段只赋值一次 err error //错误 } 主要函数
func (g *Group) Go(f func() error) { if g.sem != nil { g.sem &amp;lt;- token{} //限制并发数, 并发数由管道能容纳下的token个数决定 } g.wg.Add(1) go func() { defer g.done() if err := f(); err !</description>
    </item>
    
    <item>
      <title>AMQP 0-9-1协议</title>
      <link>https://shifengbin.github.io/posts/net/amqp/</link>
      <pubDate>Tue, 02 Aug 2022 11:06:49 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/net/amqp/</guid>
      <description>约定 下面出现的无特殊说明都是按下面对应关系
Publishers(发布者/生产者)
Consumers(消费者)
Exchanges(交换机)
Broker(中间件)
Queues(队列)
Bingdings(绑定)
AMQP是什么 AMQP是Advanced Message Queuing Protocol的缩写,高级消息队列协议,是一种消息传递协议
中间件和角色 消息中间件从Publishers(发布者/生产者)接收消息,路由到Consumers(消费者)
因为AMQP是网络协议, 发布者,消费者,中间件能够在不同的机器上.
AMQP模型简介 AMQP模型有下面的视角:
消息被发布到交换机(exchange,通常被比作邮局或邮箱) 交换机(exchanges)根据绑定(bindings)规则把消息复制到队列(queues) 中间件(borker)把消息投递到订阅队列或者从队列中拉取的消费者(consumers) 当一个消息发布时, 生产者可以设置一些消息属性(消息元数据meta data).一些元数据被中间件使用,剩下其他的被不透明发送到中间件给应用程序使用.
网络是不可靠的,应用也有可能处理消息失败,AMQP 0-9-1有一个消息应答(acknowledgements)的概念:当一个消息派发给消费者,消费者会通知中间件,可以自动执行或者开发者选择执行.当使用消息确认时,收到消息的通知就会从队列里删除该消息.
在某些情况,比如一个消息无法被路由,消息将会返回给生产者,丢弃,或者如果中间件实现一个扩展放入死信队列.生产者通过发布消息携带某些参数来处理这些情况.
队列(queue)、交换机(exchanges)和绑定(bingdings)统称为AMQP实体.
AMQP是一个可编程的协议 AMQP是一种可编程协议，AMQP的实体和路由方案主要由应用程序自己定义，而不是由中间件管理员定义.因此，为声明队列和交换机、定义它们之间的绑定、订阅队列等操作做出了规定.
这给应用程序开发者很大的自由,但是这也要求他们意识到潜在的定义冲突,在实践中定义冲突很少，通常是配置错误。
应用定义他们需要的实体,定义必要的路由规则和不在使用时删除实体
交换机和交换机类型 交换机是向其发送消息的AMQP实体,交换机接收消息并将其路由到零个或多个队列中。使用的路由算法取决于交换机类型和绑定,AMQP协议提供四种交换机类型:
交换机类型 默认名称 Direct exchange(直接交换机) (Empty string) and amq.direct Fanout exchange(扇出交换机) amq.fanout Topic exchange(主题交换机) amq.topic Headers exchange(头交换机) amq.match (and amq.headers in RabbitMQ) 除了交换机类型之外，交换机还使用许多属性来声明，其中最重要的是:
Name (名称) Durability (中间件重启后持久化) Auto-delete (最后一个队列解除绑定自动删除) Arguments (参数,可选的, 由插件和中间件特定功能使用) 交换机可以是持久的或者是临时的,持久性交换机在中间件重启后仍能存在，而暂时性交换机则不能.并非所有场景和用例都要求交换机持久化.
默认交换机 默认交换机是一个没有名称预定义在broker的直接交换机(direct exchange),它有一个特殊的特性，这使得它对于简单的应用程序非常有用:每个被创建的队列都会用和队列名称相同的路由键(routing key)自动绑定默认交换机.</description>
    </item>
    
    <item>
      <title>Fisher-Yates Shuffle</title>
      <link>https://shifengbin.github.io/posts/algorithm/shuffle/</link>
      <pubDate>Wed, 27 Jul 2022 11:41:33 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/algorithm/shuffle/</guid>
      <description> 这个算法发是今天看了一个go的代码库看到的,通过lo库看到有个Shuffle函数点进去看了一下,调用的数标准库中的shuffle算法,看了一下介绍,感觉有点意思,记录一下
Fisher-Yates算法是什么 Fisher-Yates算法 是一种生成随机排列的算法
核心原理 — To shuffle an array ‘a’ of ‘n’ elements: //对于一个规模为n的集合 for i from n-1 down to 1 do //从后向前遍历 j = random integer such that 0 &amp;lt;= j &amp;lt;= i //随机一个从0-i数字 exchange a[j] and a[i] //交换随机下标和当前下标的元素交换 用语言描述就是:
从后向前遍历 随机一个下标范围是0到当前下标,(范围包含当前下标是因为可能不交换) 交换随机下标指向的值和当前下标指向的值 go语言描述 func init(){ rand.Seed(time.Now().Unix()) } func Shuffle[T any](t []T) { for i := len(t) - 1; i &amp;gt; 0; i-- { j := rand.Int() % (i + 1) t[i], t[j] = t[j], t[i] } } </description>
    </item>
    
    <item>
      <title>语法图</title>
      <link>https://shifengbin.github.io/posts/compiler/syntax_graph/</link>
      <pubDate>Thu, 07 Jul 2022 18:00:27 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/compiler/syntax_graph/</guid>
      <description>语法图又称铁路图，是EBNF(扩展巴克斯范式)的图形化表示
从左边界开始沿着轨道去到右边界。 沿途，你将在圆框中遇到的是字面量，在方块中遇到的是规则或者描述。 任何沿着轨道能走通的序列都是合法的。 任何不能沿着轨道走通的序列都是非法的。 /* a simple program in EBNF − Wikipedia */ program ::= &amp;#39;PROGRAM&amp;#39; whiteSpace identifier whiteSpace &amp;#39;BEGIN&amp;#39; whiteSpace (assignment &amp;#34;;&amp;#34;)* &amp;#39;END.&amp;#39; assignment ::= identifier &amp;#34;:=&amp;#34; ( number | identifier | string ) string ::= &amp;#39;&amp;#34;&amp;#39; [A-Z0-9_]+ &amp;#39;&amp;#34;&amp;#39; identifier ::= [A-Z] [0-9A-Z]* whiteSpace ::= [#x20] </description>
    </item>
    
    <item>
      <title>EBNF</title>
      <link>https://shifengbin.github.io/posts/compiler/ebnf/</link>
      <pubDate>Tue, 05 Jul 2022 15:31:12 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/compiler/ebnf/</guid>
      <description>EBNF 扩展巴科斯-瑙尔范式(EBNF, Extended Backus–Naur Form) 是表达作为描述计算机编程语言形式语言(是用精确的数学或机器可处理的公式定义的语言) 的正规方式的上下文无关文法 的元语法(metalanguage)符号表示法。它是巴科斯范式(BNF) 元语法符号表示法的一种扩展。
简单的理解就是用来描述语言词法和语法规则的语言
ISO/IEC 14977标准 基本形式 LEFT=RIGHT 意思为LEFT可由RIGHT推导而来，LEFT为非终结符，RIGHT可以为非终结符也可以为终结符； 非终结符 简单的理解就是可以继续推导的符号 终结符 不可被推导的符号
符号 符号 含义 示例 = 定义 CharA=&amp;ldquo;a&amp;rdquo;; 代表CharA由字母a推导而来 , 连接符 a,b,c 代表abc是挨着的 ; 结束符 CharA=&amp;ldquo;a&amp;rdquo;; 代表 CharA这条语句定义结束 | 或者 digit = &amp;ldquo;0&amp;rdquo; | &amp;ldquo;1&amp;rdquo; | &amp;ldquo;2&amp;rdquo; | &amp;ldquo;3&amp;rdquo; | &amp;ldquo;4&amp;rdquo; | &amp;ldquo;5&amp;rdquo; | &amp;ldquo;6&amp;rdquo; | &amp;ldquo;7&amp;rdquo; | &amp;ldquo;8&amp;rdquo; | &amp;ldquo;9&amp;rdquo;; [&amp;hellip;] 可选，出现0次或1次 number = [&amp;quot;-&amp;quot;|&amp;quot;+&amp;quot;],digit 可匹配 1 -1 +1 &amp;hellip; {&amp;hellip;} 重复，出现&amp;gt;=0次 number = [&amp;quot;-&amp;quot;|&amp;quot;+&amp;quot;],digit,{digit} 可匹配 1 -1 +1 11 &amp;hellip; (&amp;hellip;) 分组 number = （&amp;quot;-&amp;quot;|&amp;quot;+&amp;quot;）,digit 符号必须添加，可匹配 -1 +1 &amp;hellip; &amp;ldquo;&amp;hellip;&amp;ldquo;或者&amp;rsquo;&amp;hellip;&#39; 终结符,单引号主要是一些特殊情况，比如双引号 &amp;ldquo;a&amp;quot;或者&amp;rsquo;a&amp;rsquo; 由单或双引号引起来的部分是终结符，就是代表字母a，不可继续推导 (* &amp;hellip; *) 注释 (*我是注释*) 注释不参与定义 ?</description>
    </item>
    
    <item>
      <title>计算机网络简要概述</title>
      <link>https://shifengbin.github.io/posts/net/summary/</link>
      <pubDate>Mon, 04 Jul 2022 21:10:39 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/net/summary/</guid>
      <description>计算机网络分层 市面上对网络分层主要是有三种分层
七层 五层 四层 应用层 应用层 应用层 表示层 会话层 传输层 传输层 传输层 网络层 网络层 网络层 数据链路层 数据链路层 网络接口层 物理层 物理层 每层的职责 物理层 提供物理介质,电压信号等功能
数据链路层 提供P2P传输 (点对点的, 比如一个路由器到另一个路由器)
网络层 提供E2E传输 (Endpoint to Endpoint,两个端点的传输,中间可能经过若干个路由器,注意区别P2P, E2E &amp;gt; P2P)
传输控制层 提供进程到进程的传输(端口到端口的传输)
应用层 应用自定义个协议
每一层都是通过下层对上层提供接口的形式来提供服务
常用网络设备 交换机 交换机工作在数据链路层, 通过mac地址进行转发, 全双工网络设备, 可以隔离碰撞域, 减少链路上的信号碰撞,提高链路网络利用率
路由器 路由器工作在网际层, 通过ip进行转发, 全双工网络设备, 可以隔离广播域(广播不能通过路由器)</description>
    </item>
    
    <item>
      <title>Semaphore(信号量)</title>
      <link>https://shifengbin.github.io/posts/go_source/semaphore/</link>
      <pubDate>Fri, 01 Jul 2022 23:51:45 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go_source/semaphore/</guid>
      <description>信号量 信号量(Semaphore)，有时被称为信号灯，是在多线程环境下使用的一种设施，是可以用来保证两个或多个关键代码段不被并发调用。在进入一个关键代码段之前，线程必须获取一个信号量；一旦该关键代码段完成了，那么该线程必须释放信号量
简单的说就是通过获取资源和释放资源来进行同步的一种策略
用法 用法一共有以下几步:
创建信号量 获取信号量 释放信号量 //1.创建信号量为10 sem = semaphore.NewWeighted(10) for i := 0; i &amp;lt;100; i++ { go func() { ctx := context.TODO() //2.获取一个信号量, 信号量一共10个,获取最多获取10,超过的gorutine会挂起 if err := sem.Acquire(ctx, 1); err != nil { doSomething() } //3. 释放信号量,1个 sem.Release(1) }() } 代码解读 Weighted 结构(NewWeighted 返回的数据结构) type Weighted struct { size int64 //总大小,就是NewWeighted传入的个数 cur int64 //当前消耗的个数 mu sync.Mutex //互斥锁 waiters list.List //等待列表, 当信号量不足时等待的列表 } waiter 结构(等待列表保存的结构) type waiter struct { n int64 //需要的资源数 ready chan&amp;lt;- struct{} // 用来通知gorutine } Acquire 方法 func (s *Weighted) Acquire(ctx context.</description>
    </item>
    
    <item>
      <title>K3s安装</title>
      <link>https://shifengbin.github.io/posts/pi/k3s/</link>
      <pubDate>Wed, 29 Jun 2022 00:02:05 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/pi/k3s/</guid>
      <description>安装步骤 根据官方文档使用 curl -sfL https://rancher-mirror.rancher.cn/k3s/k3s-install.sh | INSTALL_K3S_MIRROR=cn sh - 一条命令安装
安装过程的坑 建议使用Raspberry OS, 之前使用过Ubuntu 22.04 安装后发生节点有时Ready有时NotReady反复横跳, 最后用Raspberry OS安装成功 Raspberry也有点小坑,需要在/boot/cmdline.txt文件最后用空格,不要换行, 添加cgroup_memory=1 cgroup_enable=memory, 然后重启 `` 官方文档 </description>
    </item>
    
    <item>
      <title>链路追踪</title>
      <link>https://shifengbin.github.io/posts/micro_service/trace/</link>
      <pubDate>Mon, 27 Jun 2022 14:24:23 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/micro_service/trace/</guid>
      <description>链路追踪是什么 链路追踪是在分布式条件下将一个请求还原成一个完整调用链条,可以分析调用拓扑,延迟分析,性能分析.
链路追踪的好处 分析网络,服务耗时(通过链路追踪事件可以知道网络延迟,服务延迟) 分析网络拓扑(链路分析) 故障定位(配合日志,进行故障定位) 原理 Trace Trace代表一个调用链路,通过TraceID来标记, 一次请求调用的各个服务TraceID在全局都是唯一的
Span Span代表一个调用范围拥有(ParentID, SpanID), ParentID代表他的调用者SpanID, SpanID代表本层次调用id
通过TraceID标记一个完整调用链都调用了哪些调用过程, 通过ParendID,和SpanID还原了调用的父子关系
Annotation 通过上面三个ID只能还原调用关系, 还不能进行性能分析和定位,所以还要添加一些辅助的注解信息, 可以同定义事件比如: Client Send: 客户端调用开始 Client Receive: 客户端调用结束 Server Send: 服务端发送 Server Receive: 服务端接收
图一是一个调用关系图,展示了TraceID, SpanID, ParentID 之间的关系,和传递 其中,个方框是一个服务,箭头代表调用关系,一个完整调用链中trace是相同的, 每个服务有各自的SpanID, ParentID是调用方的SpanID, 通过这些ID我们可以知道调用的上下级关系
图二是通过Annotation附带信息进行性能分析,通过Client Send 到 Server Receive可以分析出请求服务的网络时延;通过Server Receive到Server Send可以分析出调用时延;同理Server Send到Client Receive分析出响应的网络时延, Client Send到Client Receive整个请求的时延</description>
    </item>
    
    <item>
      <title>Once</title>
      <link>https://shifengbin.github.io/posts/go_source/once/</link>
      <pubDate>Sat, 25 Jun 2022 20:50:16 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go_source/once/</guid>
      <description>once是什么 和singlefight有些相似,singlefight是并发执行时只有一个在执行, once也是并发时只有一个在执行,只不过,只执行一次,再次调用不会在执行
once怎么用 var A int var once = sync.Once{} func initA() int { once.Do(func() { //这里只会执行一次 A = 10 //A=10 只会执行一次,并且所有并发进来的,都需要等待A=10 完成后返回 }) return A // A=10 happens before 读取A, 所以initA()在所有gorutine里,都返回10 } 这个例子我们可以构造一个懒汉模式单例
源码阅读 Once结构 type Once struct { done uint32 m Mutex } Once结构很简单,只有两个字段, done来表示是否执行完成, m为互斥锁
Do函数 func (o *Once) Do(f func()) { //判断done 如果没完成,则执行doSlow函数,否则直接返回退出函数 if atomic.LoadUint32(&amp;amp;o.done) == 0 { o.doSlow(f) } } doSlow (第一次并发执行时才会进入的分支) func (o *Once) doSlow(f func()) { o.</description>
    </item>
    
    <item>
      <title>数据竞赛(Data Race)</title>
      <link>https://shifengbin.github.io/posts/go/datarace/</link>
      <pubDate>Thu, 23 Jun 2022 16:39:21 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go/datarace/</guid>
      <description> 没有安全的数据竞赛,不要使用各种炫技的无锁方式等骚操作! 什么是数据竞赛 并行程序在未使用同步方法(atomic, lock)的情况下, 并发读写共享资源就会造成数据竞争
数据竞赛检测原理 通过编译器注入检测代码, 检测代码会保存读写内存的 线程id, 时钟, 读写位置和长度, 是否写入等信息, 在运行的过程判断,读写内存是否有交叉,是否满足happens-before等条件,来判断数据竞赛
如何避免 使用同步方法去解决happens-before 比如使用atomic包, sync包 或者使用chan
go检测数据竞赛方法 使用go工具链 go build -race 编译一个带有数据竞赛检测的可执行程序,会在编译期插入代码,这种程序消耗内存和CPU是不带检测的数倍到数十倍,不可大范围用于生产环境
go run -race 直接运行一个带检测的程序(内部也经过编译)
go test -race 运行待检测的单元测试
go install -race 编译并安装一个待检测的可执行程序
注意数据竞赛检测是需要程序运行到有竞赛的代码才会检测到!运行不到的是不会检测出来的! </description>
    </item>
    
    <item>
      <title>go内存模型</title>
      <link>https://shifengbin.github.io/posts/go/memorymodel/</link>
      <pubDate>Thu, 23 Jun 2022 10:33:29 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go/memorymodel/</guid>
      <description>介绍 Go内存模型指定了一种条件，在这种条件下，可以保证读取一个goroutine中的变量，以观察不同goroutine中写入同一变量所产生的值。
建议 修改多个goroutine同时访问的数据必须序列化访问
序列化访问保护数据使用channel操作或者其他同步原语比如sync或者sync/atomic包
Happens before 在一个goroutine中,读写必须表现得就像它们按照程序指定的顺序执行一样;也就是说 在一个goroutine中,处理器和编译器可以重排读写的执行顺序,仅当重排后的行为不改变语言的设定.因为重排,一个goroutine观察到的执行顺序可能与另一个goroutine观察到的顺序不同.举个例子,如果一个goroutine执行a = 1; b = 2;,另一个可能会观察到b在a之前更新.
为了指定读写的需要，我们定义了在Go程序中执行内存操作的偏序(partial order)。如果事件$e_1$先发生于事件$e_2$我们说$e_2$后发生于$e_1$. 同样的如果$e_1$没有先发生于$e_2$并且$e_1$没有后发生于$e_2$那么我们说$e_1 e_2$同时发生.
在单个gorutine里, happens-before的顺序是程序表示的顺序.
如果下面两个条件成立,则允许变量v的读r 观察到对v的写w:
r没有先发生于w 没有其他对v的写w&amp;rsquo; ,后发生于w, 先发生于r (也就是在w 和 r之间不存在 w&#39;) 为了保证r能读到w的写,要确保w是允许r观察的唯一写入.也就是说，如果以下两个条件均成立，则保证r观察到w：
w先发生于r 任何其他写入共享变量v都要先发生于w或者后发生于r 这对条件比第一对更严格,这一对要求没有其他的写同时发生于w或r
在单个gorutine中没有并发,这两个定义是等价的:读r观察最近写入w到v的值.
在多个gorutine访问一个共享变量v,必须使用同步事件来建立happens-before条件来确保读到期望的写.
变量v的类型为零值时，变量v的初始化行为就像在内存模型中写入一样。(初始化等同于写入)
读写超过机器字(machine word)的行为就和以未指定的顺序执行多个机器字大小的操作一样(超过machine word 每个machine word 读取和写入顺序可能不是期望的)
总之, 想要在一个gorutine中读到另一个gorutine的写就要保证, 写在读之前发生,如果我们不加控制,这个写先于读的顺序就很难保证,所以我们需要使用atomic或者和lock机制来保证顺序保证happens-before
同步 初始化 程序初始化在单个goroutine中运行，但该goroutine可能会创建其他并发运行的goroutine。
如果包p导入包q，则q的init函数的完成时间在任何p的开始之前。
函数main的开始。main在所有init函数完成后发生。
Goroutine创建 启动新goroutine的go语句发生在goroutine开始执行之前。 举例
var a string func f() { print(a) } func hello() { a = &amp;#34;hello, world&amp;#34; go f() } 调用hello将在将来hello, world,可能hello已经返回</description>
    </item>
    
    <item>
      <title>false sharing</title>
      <link>https://shifengbin.github.io/posts/cpu/falsesharing/</link>
      <pubDate>Wed, 22 Jun 2022 15:04:38 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/cpu/falsesharing/</guid>
      <description>false sharing我们一般说的是多核的问题,这个问题主要出现在CPU的缓存上,我们知道CPU有多级缓存,而CPU缓存单单位是行(主流一个缓存行是64Byte, 也就是8个int64)
CPU加载缓存 当我们要操作一个变量A时会把A附近的64个字节都加载到缓存行中(空间局部性原理),这样在CPU的缓存里操作时要比在内存中要快
多核CPU缓存问题 在多核心中每个CPU核心都有自己的缓存,如果A和B变量是挨着的, 当CPU1要写A变量, CPU2读变量B, 因为AB挨着,CPU1和CPU2都把它们加载到自己的缓存中,并且AB在同一个缓存行中,CPU1改了A导致了CPU2中B缓存失效,CPUB就得重新从内存中加载缓存
这种情况就是&amp;quot;假共享&amp;quot;/&amp;ldquo;伪共享&amp;rdquo;/&amp;ldquo;false sharing&amp;rdquo;
说白了就是,CPU各自都有一份,因为邻近变量修改导致了其他核心缓存失效
例子 CASE1 type FS struct { X int64 Y int64 } func share() { var a FS wg := sync.WaitGroup{} wg.Add(2) start := time.Now() go func() { for i := 0; i &amp;lt; 100000000; i++ { a.X++ } wg.Done() }() go func() { for i := 0; i &amp;lt; 100000000; i++ { a.Y++ } wg.Done() }() wg.</description>
    </item>
    
    <item>
      <title>利特尔法则(等候理论,排队理论)</title>
      <link>https://shifengbin.github.io/posts/math/lite_rule/</link>
      <pubDate>Tue, 21 Jun 2022 22:44:01 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/math/lite_rule/</guid>
      <description>定义 在一个稳定的系统中，长期的平均顾客人数（L），等于长期的有效抵达率（λ），乘以顾客在这个系统中平均的等待时间（W）； 或者，我们可以用一个代数式来表达： $L=λW$
用白话说的话就是,在W时间内最多排多少人,能够让最后一个人也能在W时间内完成服务,也就是第一个人恰好出去,最后一个人恰好进来,这样最后一个人也能在W时间内出去
案例 就是说L的最后一名也可以在W时间内完成服务,按图上例子来说,就是4分钟内能同时服务多少个顾客 因为顾客的进入速度是2, 所以4分钟内最多也就是8个
如果进如速度是10那么4分钟就是40个
类比服务请求 如果一个请求的响应时长是1s, 系统的QPS是10/s, 那么系统同时处理请求的最佳个数是 10/s * 1s = 10个 如果系统里同时请求数超过10个,那么就会造成响应时间延长</description>
    </item>
    
    <item>
      <title>指数加权平均(EWA)</title>
      <link>https://shifengbin.github.io/posts/math/ewa/</link>
      <pubDate>Mon, 20 Jun 2022 17:44:00 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/math/ewa/</guid>
      <description>EWA是什么 EWA是以指数式递减加权的移动平均, 是一种近似平均(也可以理解为一段时间的平均值,因为越久的数据对当前的影响越小,小到一定程度就可以忽略,可以理解为一段时间的平均值)
基本公式 $V_t=βV_{t-1} + (1-β)R_t$
$V_t$ 代表t时刻的平均值
$βV_{t-1}$代表t-1时刻的平均值
$R_t$ 是t时刻的真实值
$β$ 范围在0-1之间
平均天数为 $N=\frac {1} {1-β}$
$β=0.5$则平均个数N=2 $β=0.9$则平均个数N=$\frac{1}{1-0.9}=10$ 也就是平均最近10次的
可以做什么 计算$\frac {1} {1-β}$个数据的平均值,减少噪声影响,平滑数据
好处比其他平均的好处是 不需要保存最近N次的数据,只需要保存上次计算的平均值</description>
    </item>
    
    <item>
      <title>hugo 支持github评论</title>
      <link>https://shifengbin.github.io/posts/hugo/comments/</link>
      <pubDate>Mon, 20 Jun 2022 15:02:41 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/hugo/comments/</guid>
      <description> 先在utteranc的configuration部分找到安装utteranc app到仓库,选择一个仓库并安装 在页面Enable Utterances部分找到js代码 在自己用的主题上找到关于comment的layout,把js代码添加到里面 运行 </description>
    </item>
    
    <item>
      <title>go sync包之singleflight原理</title>
      <link>https://shifengbin.github.io/posts/go_source/sync_singleflight/</link>
      <pubDate>Sun, 19 Jun 2022 22:02:23 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/go_source/sync_singleflight/</guid>
      <description>singlefight是什么 singlefight 直译为&amp;quot;单飞&amp;quot;(雅名到底是啥我也不知道), 顾名思义就是只有一个跑了, 是用来对同一资源控制并发 多个goroutine访问同一个资源时,只有一个goroutine真正的进行访问,其他goroutine等待这一个goroutine返回后共享返回结果
为什么出现singlefight 这个包 上面是什么中已经交代,是为了控制访问同一个资源的并发数,举个例子:假设有个接口访问数据库中id为1的一条数据,如果我们没有控制并发,那么来一百个并发访问这个数据,那么这一百个请求全部取请求数据库(即使有缓存也是全部请求缓存)
如果我们使用了singlefight那么,100个并发讲只有一个请求去数据库,其他99个全部共享那1个返回的结果
怎么用 var g = singleflight.Group{} //初始化了一个singleflight func SharedRes(id int) (int, error) { key := fmt.Sprintf(&amp;#34;id:%d&amp;#34;, id) //同一个group上,相同key的,只会执行一次,也就是说用key标识一个共享资源 ret, err, _ := g.Do(key, func() (interface{}, error) { //调用共享资源 time.Sleep(time.Second) //这里睡1s是模拟资源执行的延迟 fmt.Println(&amp;#34;xxxx&amp;#34;) return 1, nil }) return ret.(int), err } func SingleFlight() { wg := sync.WaitGroup{} //为了等100个goroutine执行完,开启了一个WaitGroup for i := 0; i &amp;lt; 100; i++ { wg.Add(1) go func() { //模拟并发 ret, err := SharedRes(1) fmt.</description>
    </item>
    
    <item>
      <title>redis分布式锁</title>
      <link>https://shifengbin.github.io/posts/micro_service/redis_lock/</link>
      <pubDate>Sat, 18 Jun 2022 21:24:37 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/micro_service/redis_lock/</guid>
      <description>redis分布式锁网上方案很多,这里简单的介绍一种
加锁步骤 1.创建锁对象,内部创建一个随机数
2.使用SET KEY VALUE NX EX xxxSecond, 如果成功创建了KEY 则证明加锁成功VALUE 就是第一步创建的随机数 3.如果未能成功加锁需要不断取重试,直到超时或者获取锁
解锁步骤 解锁需要去判断KEY对应的值是否是创建时的随机数,如果不是就不能删除,只有是的时候才能删除,因为如果不是自己的随机数可能是因为锁过期被别人加锁了,不能去删除别人的锁, 检查和删除必须是原子操作,所以我们可以使用lua脚本保证原子操作
if redis.call(&amp;#34;GET&amp;#34;, KEYS[1])==ARGV[1] then redis.call(&amp;#34;DEL&amp;#34;, KEYS[1]) return true else	return false end 上面的lua脚本很容易懂,就是用来判断key对应的值是否是参数的值,如果是就删除key并返回成功,否则返回失败;失败的情况就是上述说的锁过期被其他程序加锁
优化 加锁是需要不断去重试,访问次数过多可能会给redis造成压力,比如100ms抢一次,一个线程1s钟要请求redis 10次, 如果是10线程抢锁,那么1s就是100次,抢锁的越多就会将redis请求数放大10倍 应对这种情况我们可以考虑,进程内部先去加互斥锁,解锁的时候去解互斥锁, 然后抢到锁的线程再去抢redis锁
优点: 这样如果有两个进程,各有5个线程去抢锁,则实际只有两个线程去访问redis,抢到锁后只有另一个进程的1个线程继续抢,这种已经在生产环境中得到实践
缺点: 造成锁竞争的不公平,同一个进程其他线程更容易抢到锁,因为互斥锁解锁同一个进程的其他线程可以更快的感知
还有一种想法未得到验证,通过redis的发布订阅来改进锁性能
锁过期问题,没有个安全的方法去估计过期时间 针对这种情况,可以考虑锁续期逻辑,比如默认过期时间是30s,我们到20s的时候去延长过期时间
可以考虑使用下面的续期逻辑
if redis.call(&amp;#34;GET&amp;#34;, KEYS[1]) == ARGV[1] then redis.call(&amp;#34;EXPIRE&amp;#34;, KEYS[1], ARGV[2]) return true else return false end 先去判断锁是否是自己的,如果是则进行续期
参考资料 redis set命令 从2.6.12版本开始，redis为SET命令增加了一系列选项
EX seconds – 设置键key的过期时间单位时秒
PX milliseconds – 设置键key的过期时间单位时毫秒</description>
    </item>
    
    <item>
      <title>树莓派 连接WIFI</title>
      <link>https://shifengbin.github.io/posts/pi/connect_wifi/</link>
      <pubDate>Sat, 18 Jun 2022 21:15:30 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/pi/connect_wifi/</guid>
      <description>ubuntu 22.04 进入 /etc/netplan/ 文件夹 cd /etc/netplan/ 编辑里面唯一一个文件，大概是：50-cloud-init.yaml sudo vim 50-cloud-init.yaml, 需要使用sudo,因为这个文件是root用户的问题件,或者把文件选项改成可写的 添加WIFI配置 network: ethernets: eth0: dhcp4: true optional: true wifis: # &amp;lt;----添加wifi配置节点 wlan0: dhcp4: true optional: true access-points: &amp;#34;wifi_name&amp;#34;: #&amp;lt;---- 这里填写填写你要连接的wifi名称 password: &amp;#34;xxxxx&amp;#34; #&amp;lt;-------这里填写wifi密码 version: 2 执行命令,生成网络配置sudo netplan generate 使网络配置生效sudo netplan apply 树莓派系统 在命令行中输入sudo raspi-config根选项配置即可(注意,可能不支持5G信号)</description>
    </item>
    
    <item>
      <title>Mac用网线连接树莓派</title>
      <link>https://shifengbin.github.io/posts/pi/pi_connect_mac/</link>
      <pubDate>Sat, 18 Jun 2022 16:12:36 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/pi/pi_connect_mac/</guid>
      <description> 首先 打开mac的系统偏好设置-&amp;gt;共享-&amp;gt;互联网共享（USB 10/100/1000 LAN） 并打开共享 打开终端查看树莓派分配的IP 使用arp -a 里面有个带有bridgeXXX的 IP 使用ssh命令 远程连接 </description>
    </item>
    
    <item>
      <title>Contact</title>
      <link>https://shifengbin.github.io/contact/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://shifengbin.github.io/contact/</guid>
      <description>We&amp;#39;d love to hear from you</description>
    </item>
    
  </channel>
</rss>
