<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Kafka on Blog Zone</title>
    <link>https://shifengbin.github.io/tags/kafka/</link>
    <description>Recent content in Kafka on Blog Zone</description>
    <image>
      <title>Blog Zone</title>
      <url>https://shifengbin.github.io/images/cover.jpg</url>
      <link>https://shifengbin.github.io/images/cover.jpg</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>zh</language>
    <lastBuildDate>Thu, 04 Jul 2024 15:16:44 +0800</lastBuildDate><atom:link href="https://shifengbin.github.io/tags/kafka/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Kafka使用kraft搭建集群</title>
      <link>https://shifengbin.github.io/posts/mq/kafka_kraft/</link>
      <pubDate>Thu, 04 Jul 2024 15:16:44 +0800</pubDate>
      
      <guid>https://shifengbin.github.io/posts/mq/kafka_kraft/</guid>
      <description>主机准备
主机 IP 系统 kafka1 192.168.10.101 ubuntu22.04 kafka2 192.168.10.102 ubuntu22.04 kafka3 192.168.10.103 ubuntu22.04 主机环境
安装java17 kafka_2.13-3.7.0 配置
这里部署的是broker和controller在一起的方式,也可以分别部署,具体修改kraft相关文件,配置都是相通的
kafka/config/kraft/server.properties
#集群角色 process.roles=broker,controller #每台机器的id不能一样 node.id=3 #这个是所有conntroller的地址,用于投票选举使用 controller.quorum.voters=1@192.168.10.101:9093,2@192.168.10.102:9093,3@192.168.10.103:9093 # 监听端口 listeners=PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093 # 客户端连接地址 advertised.listeners=PLAINTEXT://192.168.20.208:9092 # 日志地址, 这个修改到非/tmp目录,否则系统重启后会丢失 log.dirs=/var/log/kafka/kraft-combined-logs # ...其他配置按照实际情况修改 启动集群步骤:
KAFKA_CLUSTER_ID=&amp;quot;$(bin/kafka-storage.sh random-uuid)&amp;quot; 这个操作只在一个机器上运行,执行后记录这个值,这个是集群id,整个集群需要一致
bin/kafka-storage.sh format -t $KAFKA_CLUSTER_ID -c config/kraft/server.properties 每个机器上都要执行, 这个KAFKA_CLUSTER_ID 就是是上面执行的值
bin/kafka-server-start.sh config/kraft/server.properties 启动集群
配置systemd开机启动
在/etc/systemd/system/kafka.service文件中添加内容
[Unit] Description=Apache Kafka Server [Service] Type=simple User=root Group=root ExecStart=/usr/local/kafka/bin/kafka-server-start.sh /usr/local/kafka/config/kraft/server.properties ExecStop=/usr/local/kafka/bin/kafka-server-stop.sh Restart=on-failure [Install] WantedBy=multi-user.target 执行sudo systemctl daemon-reload 重新加载 执行sudo systemctl enable kafka 开机启动 执行sudo systemctl start kafka 启动 使用sudo journalctl -u kafka.</description>
    </item>
    
  </channel>
</rss>
